{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from scipy.signal import lfilter, butter, decimate, hann\n",
    "import scipy.stats as stats\n",
    "import datetime\n",
    "from time import localtime, strftime\n",
    "import warnings\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, Callback\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Conv1D, SpatialDropout1D, Flatten, Activation, Lambda, Convolution1D, Dense, add\n",
    "\n",
    "from UTILS import *\n",
    "from wfdisc_utils import WFDISC\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "model_folder='models/'\n",
    "log_folder='logs/'\n",
    "if not os.path.exists(model_folder):\n",
    "    os.mkdir(model_folder)\n",
    "if not os.path.exists(log_folder):\n",
    "    os.mkdir(log_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# DeepPick:\n",
    "\n",
    "This Notebook details the development of a simple Picking algorithm for three-component Seismograms:\n",
    "\n",
    "\n",
    "We will proceed in three parts:\n",
    "\n",
    "1) Data Wrangling\n",
    "\n",
    "2) Model Architecture\n",
    "\n",
    "3) Training and Testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: Data Wrangling\n",
    "\n",
    "### Load Bulletin:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cat(filename):\n",
    "    cat = pd.read_csv(filename, index_col=0)\n",
    "    cat['TIME'] = pd.to_datetime(cat['TIME'])\n",
    "    cat.fillna('', inplace=True)\n",
    "    cat = cat.sort_values(by=['TIME'])\n",
    "    cat.reset_index(drop=True, inplace=True)\n",
    "    return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat = read_cat('data/IDCLEB_arrivals_arrays_13_15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P', 'LR', 'tx', 'Pn', 'N', 'Sx', 'PcP', 'Lg', 'Sn', 'S', 'PKP', 'Pg', 'ScP', 'pP', 'PP', 'Px', 'PKi', 'PKK', 'Rg', 'SKP', 'Pdi', 'ScS', 'P3K', 'pPK', 'PKh', 'sP', 'P4K', 'SKK', 'Sdi', 'SKi']\n"
     ]
    }
   ],
   "source": [
    "print(list(cat.IPHASE.value_counts().index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Training Catalog\n",
    "stations = ['ASAR', 'ILAR', 'MKAR', 'NVAR', 'PDAR', 'TXAR']\n",
    "start_time = '2013-01-01'\n",
    "end_time = '2014-01-01'\n",
    "# Specify the phases you wish to train on\n",
    "phases = ['P', 'Pn', 'Pc', 'PcP', 'PK', 'Pg', 'PKP', 'pP', 'PP', 'Px']\n",
    "\n",
    "# Build Training Catalog\n",
    "cat =  cat.loc[(cat.STA.isin(stations)) &                    \n",
    "                (cat.TIME > start_time) & \n",
    "                (cat.TIME < end_time)  &\n",
    "                (cat.IPHASE.isin(phases))\n",
    "              ].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P    172429\n",
       "Name: PHASE_TYPE, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase_type_dict = {}\n",
    "phase_type_map = {}\n",
    "\n",
    "# phase_type_dict['regional_P'] = ['Pn', 'Pg']\n",
    "# phase_type_dict['teleseis_P'] = ['P', 'PKP', 'pP', 'I', 'sP', 'PKKPbc', 'PKP2', 'PP', 'PcP', 'SKPbc', 'PKiKP', 'pPKP', 'PKPbc', 'SKP', 'ScP', 'SKKPbc']\n",
    "# phase_type_dict['secondary']  = ['Sn', 'S', 'ScS', 'Rg', 'I', 'LR']\n",
    "# phase_type_dict['surface']    = ['Lg']\n",
    "phase_type_dict['P'] = ['P', 'Pn', 'Pc', 'PcP', 'PK', 'Pg', 'PKP', 'pP', 'PP', 'Px']\n",
    "\n",
    "# create the mapping dictionary:\n",
    "for typ in phase_type_dict:\n",
    "    phase_type_map.update({k:v for (k,v) in [(p, typ) for p in phase_type_dict[typ]]})\n",
    "    \n",
    "# create the new 'PHASE_TYPE' column and fill it with the assigned types:\n",
    "cat['PHASE_TYPE'] = cat.IPHASE.map(phase_type_map)\n",
    "\n",
    "# Check the class imbalance of the newly defined types:\n",
    "cat.PHASE_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now save the catalog and display its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime2epoch(timestamp):\n",
    "    return (timestamp - datetime.datetime(1970, 1, 1)).total_seconds()\n",
    "\n",
    "def get_wav(sta, st_time, en_time, pdict, data_dir='data/css'):\n",
    "    cmpts = pdict['cmpts']\n",
    "    \n",
    "    X = []\n",
    "    date = st_time.strftime('%Y-%-m-%-d')\n",
    "    day = f'{st_time.timetuple().tm_yday:03d}'\n",
    "        \n",
    "    file = os.path.join(data_dir, f'{date}/{sta}.{st_time.year}{day}.wfdisc')\n",
    "    wf = WFDISC(file)\n",
    "\n",
    "    if sta[-2:] == 'AR':\n",
    "        sta = sta[:-2] + '31'\n",
    "        \n",
    "    for chan in ['BH' + l for l in cmpts]:\n",
    "        X.append(wf.getData(sta, chan, datetime2epoch(st_time), datetime2epoch(en_time)))\n",
    "    X = np.stack(X, axis=-1)\n",
    "    \n",
    "    if X.shape == (int(pdict['w_len'] * pdict['r_smp']), len(pdict['cmpts'])):\n",
    "        return X\n",
    "    else:\n",
    "        raise Exception()\n",
    "\n",
    "def DAT_normalize(X):\n",
    "    X = X - np.expand_dims(np.mean(X,1),1)\n",
    "    X = X / np.expand_dims(np.expand_dims(np.abs(X).max(1).max(1), 1), 1)\n",
    "    return X\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=8):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def DAT_filter(X, pdict, order=3):\n",
    "    lowcut = pdict['f_low']\n",
    "    highcut = pdict['f_hig']\n",
    "    fs = pdict['r_smp']\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    return lfilter(b, a, X, axis=1) \n",
    "\n",
    "def DAT_taper(X, taper_percentage=.05):\n",
    "    npts = X.shape[1]\n",
    "    taper_len = int(npts * taper_percentage)\n",
    "    taper_sides = hann(2 * taper_len + 1)\n",
    "    taper = np.hstack((taper_sides[:taper_len], np.ones(npts - taper_len)))\n",
    "    return X * np.reshape(taper,(1,-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "No Valid CSS Segments were read. Check your path.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7c6c8cd166a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0men\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrival\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTIME\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'w_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m's'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mseis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-dc1396ba81c3>\u001b[0m in \u001b[0;36mget_wav\u001b[0;34m(sta, st_time, en_time, pdict, data_dir)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{date}/{sta}.{st_time.year}{day}.wfdisc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mwf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWFDISC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'AR'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/deep-pick/wfdisc_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath)\u001b[0m\n\u001b[1;32m    116\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchan\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegments\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No Valid CSS Segments were read. Check your path.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         '''\n",
      "\u001b[0;31mException\u001b[0m: No Valid CSS Segments were read. Check your path."
     ]
    }
   ],
   "source": [
    "pdict = {}\n",
    "pdict['f_low'] = 1\n",
    "pdict['f_hig'] = 4\n",
    "pdict['r_smp'] = 40\n",
    "pdict['cmpts'] = 'ZNE'\n",
    "pdict['w_len'] = 60\n",
    "\n",
    "arrival = cat.sample().iloc[0]\n",
    "sta = arrival.STA\n",
    "st = arrival.TIME - pd.Timedelta(pdict['w_len']/2, 's')\n",
    "en = arrival.TIME + pd.Timedelta(pdict['w_len']/2, 's')\n",
    "\n",
    "seis = get_wav(sta, st, en, pdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-03f2b8b2ed78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDAT_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'seis' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(DAT_filter(np.expand_dims(seis,0), pdict)[0,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Characteristic Function from catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_c(c_width_in_samples, c_shape=None, c_amplitude=1, c_buffer_in_samples=0):\n",
    "\n",
    "    if c_shape == 'gauss':\n",
    "        x = stats.norm.pdf(np.linspace(-3, 3, c_width_in_samples))\n",
    "        x = (x - x.min()) / (x - x.min()).max()\n",
    "    else:\n",
    "        x = np.ones(c_width_in_samples)\n",
    "\n",
    "    return np.hstack([np.zeros(c_buffer_in_samples), x*c_amplitude])\n",
    "\n",
    "\n",
    "def get_cFunc(indices, pdict):\n",
    "    \n",
    "    w_tot_samps = int(pdict['r_smp'] * pdict['w_len'])\n",
    "    c_len_samps = int(pdict['r_smp'] * pdict['c_len'])\n",
    "    c_buf_samps = int(pdict['r_smp'] * pdict['c_buf'])\n",
    "    c_tot_samps = c_len_samps + c_buf_samps\n",
    "    \n",
    "    cFunc = np.zeros((w_tot_samps, 1))\n",
    "\n",
    "    for idx in indices:\n",
    "        c1 = cFunc[idx:idx + c_tot_samps, 0]\n",
    "        c2 = get_c(c_len_samps, pdict['c_shp'], pdict['c_amp'], c_buf_samps)[:len(c1)]\n",
    "        cFunc[idx:idx + c_tot_samps, 0] = np.maximum(c1, c2)\n",
    "            \n",
    "    return cFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "No Valid CSS Segments were read. Check your path.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7be1c4720176>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mpdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nb_cl'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPHASE_TYPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mseis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mcFunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-dc1396ba81c3>\u001b[0m in \u001b[0;36mget_wav\u001b[0;34m(sta, st_time, en_time, pdict, data_dir)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{date}/{sta}.{st_time.year}{day}.wfdisc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mwf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWFDISC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'AR'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/deep-pick/wfdisc_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath)\u001b[0m\n\u001b[1;32m    116\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchan\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegments\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No Valid CSS Segments were read. Check your path.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         '''\n",
      "\u001b[0;31mException\u001b[0m: No Valid CSS Segments were read. Check your path."
     ]
    }
   ],
   "source": [
    "depth = len(cat.PHASE_TYPE.unique())+1\n",
    "\n",
    "arrival = cat.sample().iloc[0]\n",
    "win_len = 30\n",
    "sta = arrival.STA\n",
    "st = arrival.TIME - pd.Timedelta(win_len/2, 's')\n",
    "en = arrival.TIME + pd.Timedelta(win_len/2, 's')\n",
    "\n",
    "my_cat = cat.loc[(cat.STA == sta) & (cat.TIME >= st) & (cat.TIME <= en)]\n",
    "arr_idx = [int(np.floor((t - st).total_seconds() * pdict['r_smp'])) for t in my_cat.TIME]\n",
    "\n",
    "pdict={}\n",
    "pdict['w_len'] = 30\n",
    "pdict['c_len'] = 1\n",
    "pdict['c_buf'] = 0\n",
    "pdict['c_shp'] = 'gauss'\n",
    "pdict['c_amp'] = 1\n",
    "pdict['f_low'] = 1\n",
    "pdict['f_hig'] = 4\n",
    "pdict['r_smp'] = 40\n",
    "pdict['cmpts'] = 'ZNE'\n",
    "pdict['task'] = 'c'\n",
    "pdict['nb_cl'] = len(cat.PHASE_TYPE.unique())\n",
    "\n",
    "seis = get_wav(sta, st, en, pdict)\n",
    "cFunc = get_cFunc(arr_idx, pdict)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10,5), sharex=True)\n",
    "_ = ax[0].plot(seis)\n",
    "_ = ax[1].plot(cFunc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2: Model Architecture\n",
    "\n",
    "### Deep Temporal Convolutional Neural Network:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RecFldLen(pdict):\n",
    "    # Code to calculate the receptive field length of the neural network\n",
    "    r = 0\n",
    "    for d in pdict['d']:\n",
    "        r = r + d * (pdict['k']-1)\n",
    "    return f'{r/pdict[\"r_smp\"]} seconds'\n",
    "\n",
    "def residual_block(x, dilation_rate, nb_filters, kernel_size, padding, dropout_rate=0):\n",
    "    prev_x = x\n",
    "    for k in range(2):\n",
    "        x = Conv1D(filters=nb_filters,\n",
    "                   kernel_size=kernel_size,\n",
    "                   dilation_rate=dilation_rate,\n",
    "                   padding=padding)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "\n",
    "    # 1x1 conv to match the shapes (channel dimension).\n",
    "    prev_x = Conv1D(nb_filters, 1, padding='same')(prev_x)\n",
    "    res_x = add([prev_x, x])\n",
    "    return res_x, x\n",
    "\n",
    "\n",
    "def encoder_network(pdict, padding='causal', drop=0.05):\n",
    "    \n",
    "    nb_chan    = len([char for char in pdict['cmpts']])\n",
    "    nb_filters = pdict['f']\n",
    "    filter_len = pdict['k']\n",
    "    dilations  = pdict['d']\n",
    "    nb_stacks  = pdict['s']\n",
    "    \n",
    "    o_act = 'sigmoid'\n",
    "    if pdict['c_shp'] == 'gauss':\n",
    "        o_act = 'linear'\n",
    "    \n",
    "    input_layer = Input(shape=(None, nb_chan))\n",
    "\n",
    "    x = input_layer\n",
    "\n",
    "    skip_connections = []\n",
    "    for s in range(nb_stacks):\n",
    "        for d in dilations:\n",
    "            x, skip_out = residual_block(x,\n",
    "                                         dilation_rate=d,\n",
    "                                         nb_filters=nb_filters,\n",
    "                                         kernel_size=filter_len,\n",
    "                                         padding=padding,\n",
    "                                         dropout_rate=drop)\n",
    "            skip_connections.append(skip_out)\n",
    "\n",
    "    x = add(skip_connections)\n",
    "\n",
    "    output_layer = Dense(1, activation=o_act, name='output')(x)\n",
    "\n",
    "    return Model(input_layer, output_layer, name='encoder_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_custom_model(pdict, model_folder='models'):\n",
    "\n",
    "    if 'iniW' in pdict.keys():\n",
    "        model_name = [n for n in os.listdir(model_folder) if f'|time:{pdict[\"iniW\"]}' in n][0]\n",
    "        model_file = os.path.join(model_folder, model_name)\n",
    "\n",
    "        print('loading previous model:\\n', model_file)\n",
    "        pdict = name2param(os.path.basename(model_file))\n",
    "        model = load_model(model_file)\n",
    "    else:\n",
    "        model_name = param2name(pdict)\n",
    "        model_file = os.path.join(model_folder, model_name)\n",
    "\n",
    "        print('building new model:\\n', model_file)\n",
    "        model = encoder_network(pdict)\n",
    "\n",
    "    loss = 'binary_crossentropy'\n",
    "    if pdict['c_shp'] == 'gauss':\n",
    "        loss = 'mse'\n",
    "                      \n",
    "    o = Adam(lr=pdict['lr'], clipnorm=1.)\n",
    "                      \n",
    "    model.compile(loss=loss, optimizer=o)\n",
    "    print(f'Receptive Field Length: {RecFldLen(pdict)}')\n",
    "\n",
    "    return model, model_name\n",
    "\n",
    "\n",
    "\n",
    "def get_callbacks(model_name, model_folder, log_folder):\n",
    "    pdict = name2param(os.path.basename(model_name))\n",
    "    tensor_foldername = os.path.join(log_folder, model_name)\n",
    "    model_filename = os.path.join(model_folder, model_name + '.h5')\n",
    "\n",
    "    sv = ModelCheckpoint(filepath=model_filename, monitor='val_loss', save_best_only=True,\n",
    "                         save_weights_only=False, mode='min')\n",
    "    tbd = TensorBoard(log_dir=tensor_foldername)\n",
    "    stp = EarlyStopping(monitor='val_loss', min_delta=0, patience=pdict['pat'],\n",
    "                        verbose=0, mode='min', baseline=None)\n",
    "\n",
    "    return [sv, tbd, stp]\n",
    "\n",
    "\n",
    "def param2name(pdict):\n",
    "    name = []\n",
    "    for key in pdict.keys():\n",
    "        if type(pdict[key]) is list:\n",
    "            name.append(f'{key}:{\"x\".join(map(str, pdict[key]))}')\n",
    "        else:\n",
    "            name.append(f'{key}:{pdict[key]}')\n",
    "    return '|'.join(name)\n",
    "\n",
    "\n",
    "def name2param(name):\n",
    "    regnumber = re.compile(r'^\\d+(\\.\\d+)?$')\n",
    "    pdict = dict([p.split(':') for p in name.split('|')])\n",
    "    for key in pdict.keys():\n",
    "        if regnumber.match(pdict[key]):\n",
    "            try:\n",
    "                pdict[key] = int(pdict[key])\n",
    "            except:\n",
    "                pdict[key] = float(pdict[key])\n",
    "        else:\n",
    "            if 'x' in pdict[key][:-1]:\n",
    "                pdict[key] = list(map(int, pdict[key].split('x')))\n",
    "            try:\n",
    "                pdict[key] = float(pdict[key])\n",
    "            except:\n",
    "                pass\n",
    "    return pdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(cat, pdict):\n",
    "    bs = pdict['bs']\n",
    "    w_len_samps = int(pdict['r_smp'] * pdict['w_len'])\n",
    "    cat = cat.copy().loc[cat.SNR > pdict['w_snr']]\n",
    "    nb_chans = len(pdict['cmpts'])\n",
    "    \n",
    "    while 1:\n",
    "        X = np.zeros((bs, w_len_samps, nb_chans))\n",
    "        Y = np.zeros((bs, w_len_samps, 1))\n",
    "        \n",
    "        batch_counter = 0\n",
    "\n",
    "        while batch_counter < bs:\n",
    "            \n",
    "            try:\n",
    "\n",
    "                rec = cat.sample().iloc[0]\n",
    "                sta = rec.STA\n",
    "                st = rec.TIME - pd.Timedelta(pdict['w_len'] / 2, 's')\n",
    "                en = rec.TIME + pd.Timedelta(pdict['w_len'] / 2, 's')\n",
    "                trace = get_wav(sta, st, en, pdict)\n",
    "                \n",
    "                my_cat = cat.loc[(cat.STA == sta) & (cat.TIME >= st) & (cat.TIME <= en)]\n",
    "                arr_idx = [int(np.floor((t - st).total_seconds() * pdict['r_smp'])) for t in my_cat.TIME]\n",
    "                cFunc = get_cFunc(arr_idx, pdict)\n",
    "\n",
    "                X[batch_counter], Y[batch_counter] = trace, cFunc\n",
    "                batch_counter += 1\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if not pdict['c_shp'] == 'gauss':\n",
    "            Y = Y > 0\n",
    "\n",
    "        X = DAT_normalize(DAT_taper(DAT_filter(X, pdict)))\n",
    "        yield X, Y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdict={}\n",
    "pdict['bs']    = 20\n",
    "pdict['w_len'] = 300\n",
    "pdict['c_len'] = 2\n",
    "pdict['c_buf'] = 0\n",
    "pdict['w_snr'] = 40\n",
    "pdict['c_shp'] = 'gauss'\n",
    "pdict['c_amp'] = 1\n",
    "pdict['f_low'] = 1\n",
    "pdict['f_hig'] = 4\n",
    "pdict['r_smp'] = 40\n",
    "pdict['cmpts'] = 'ZNE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_gen = gen(cat, pdict)\n",
    "XX, YY = next(my_gen)\n",
    "\n",
    "idx = np.random.randint(pdict['bs'])\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10,5), sharex=True)\n",
    "_ = ax[0].plot(XX[idx])\n",
    "_ = ax[1].plot(YY[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3: Train and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition Data:\n",
    "\n",
    "We now split the dataset into three partitions: Train, Validation and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_trn = cat.loc[cat.TIME <= '2013-11-01']\n",
    "cat_val = cat.loc[(cat.TIME > '2013-11-01') & (cat.TIME <= '2013-12-01')]\n",
    "cat_tst = cat.loc[cat.TIME > '2013-12-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set \n",
      "----------------------\n",
      "START TIME: 2013-01-01 00:00:22.250000\n",
      "  END TIME: 2013-10-31 23:59:49.591500\n",
      "# STATIONS: 6\n",
      "# ARIV (P): 145777\n",
      "\n",
      "\n",
      "Validation Set \n",
      "----------------------\n",
      "START TIME: 2013-11-01 00:01:07.200000\n",
      "  END TIME: 2013-11-30 23:54:11.150000\n",
      "# STATIONS: 6\n",
      "# ARIV (P): 13132\n",
      "\n",
      "\n",
      "Test Set \n",
      "----------------------\n",
      "START TIME: 2013-12-01 00:08:10.875000\n",
      "  END TIME: 2013-12-31 23:59:42.930950\n",
      "# STATIONS: 6\n",
      "# ARIV (P): 13520\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, my_cat in [('Training Set', cat_trn), ('Validation Set', cat_val), ('Test Set', cat_tst)]:\n",
    " \n",
    "    print(name,'\\n----------------------')\n",
    "    print('START TIME:', my_cat.TIME.min())\n",
    "    print('  END TIME:', my_cat.TIME.max())\n",
    "    print('# STATIONS:', len(my_cat.STA.unique()))\n",
    "    for phs in cat.PHASE_TYPE.unique():\n",
    "        print(f'# ARIV ({phs}):', len(my_cat.loc[my_cat.PHASE_TYPE == phs]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model:\n",
    "\n",
    "basic training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building new model:\n",
      " models/f:45|k:15|d:1x2x4x8x16|s:2|bs:20|c_len:2|w_snr:10|c_buf:10|c_shp:gauss|c_amp:1|f_low:1|f_hig:10|r_smp:40|cmpts:ZNE|lr:0.0001|pat:10|w_len:180\n",
      "Receptive Field Length: 10.85 seconds\n",
      "Model: \"encoder_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_240 (Conv1D)             (None, None, 45)     2070        input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, None, 45)     0           conv1d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_160 (SpatialD (None, None, 45)     0           activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_241 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_160[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, None, 45)     0           conv1d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_161 (SpatialD (None, None, 45)     0           activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_242 (Conv1D)             (None, None, 45)     180         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_88 (Add)                    (None, None, 45)     0           conv1d_242[0][0]                 \n",
      "                                                                 spatial_dropout1d_161[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_243 (Conv1D)             (None, None, 45)     30420       add_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, None, 45)     0           conv1d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_162 (SpatialD (None, None, 45)     0           activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_244 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_162[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, None, 45)     0           conv1d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_163 (SpatialD (None, None, 45)     0           activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_245 (Conv1D)             (None, None, 45)     2070        add_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_89 (Add)                    (None, None, 45)     0           conv1d_245[0][0]                 \n",
      "                                                                 spatial_dropout1d_163[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_246 (Conv1D)             (None, None, 45)     30420       add_89[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, None, 45)     0           conv1d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_164 (SpatialD (None, None, 45)     0           activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_247 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_164[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, None, 45)     0           conv1d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_165 (SpatialD (None, None, 45)     0           activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_248 (Conv1D)             (None, None, 45)     2070        add_89[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_90 (Add)                    (None, None, 45)     0           conv1d_248[0][0]                 \n",
      "                                                                 spatial_dropout1d_165[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_249 (Conv1D)             (None, None, 45)     30420       add_90[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, None, 45)     0           conv1d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_166 (SpatialD (None, None, 45)     0           activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_250 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_166[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, None, 45)     0           conv1d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_167 (SpatialD (None, None, 45)     0           activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_251 (Conv1D)             (None, None, 45)     2070        add_90[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_91 (Add)                    (None, None, 45)     0           conv1d_251[0][0]                 \n",
      "                                                                 spatial_dropout1d_167[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_252 (Conv1D)             (None, None, 45)     30420       add_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, None, 45)     0           conv1d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_168 (SpatialD (None, None, 45)     0           activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_253 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_168[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, None, 45)     0           conv1d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_169 (SpatialD (None, None, 45)     0           activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_254 (Conv1D)             (None, None, 45)     2070        add_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_92 (Add)                    (None, None, 45)     0           conv1d_254[0][0]                 \n",
      "                                                                 spatial_dropout1d_169[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_255 (Conv1D)             (None, None, 45)     30420       add_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, None, 45)     0           conv1d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_170 (SpatialD (None, None, 45)     0           activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_256 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_170[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, None, 45)     0           conv1d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_171 (SpatialD (None, None, 45)     0           activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_257 (Conv1D)             (None, None, 45)     2070        add_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_93 (Add)                    (None, None, 45)     0           conv1d_257[0][0]                 \n",
      "                                                                 spatial_dropout1d_171[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_258 (Conv1D)             (None, None, 45)     30420       add_93[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, None, 45)     0           conv1d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_172 (SpatialD (None, None, 45)     0           activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_259 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_172[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, None, 45)     0           conv1d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_173 (SpatialD (None, None, 45)     0           activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_260 (Conv1D)             (None, None, 45)     2070        add_93[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_94 (Add)                    (None, None, 45)     0           conv1d_260[0][0]                 \n",
      "                                                                 spatial_dropout1d_173[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_261 (Conv1D)             (None, None, 45)     30420       add_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, None, 45)     0           conv1d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_174 (SpatialD (None, None, 45)     0           activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_262 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_174[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, None, 45)     0           conv1d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_175 (SpatialD (None, None, 45)     0           activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_263 (Conv1D)             (None, None, 45)     2070        add_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_95 (Add)                    (None, None, 45)     0           conv1d_263[0][0]                 \n",
      "                                                                 spatial_dropout1d_175[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_264 (Conv1D)             (None, None, 45)     30420       add_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, None, 45)     0           conv1d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_176 (SpatialD (None, None, 45)     0           activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_265 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_176[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, None, 45)     0           conv1d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_177 (SpatialD (None, None, 45)     0           activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_266 (Conv1D)             (None, None, 45)     2070        add_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_96 (Add)                    (None, None, 45)     0           conv1d_266[0][0]                 \n",
      "                                                                 spatial_dropout1d_177[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_267 (Conv1D)             (None, None, 45)     30420       add_96[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, None, 45)     0           conv1d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_178 (SpatialD (None, None, 45)     0           activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_268 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_178[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, None, 45)     0           conv1d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_179 (SpatialD (None, None, 45)     0           activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_98 (Add)                    (None, None, 45)     0           spatial_dropout1d_161[0][0]      \n",
      "                                                                 spatial_dropout1d_163[0][0]      \n",
      "                                                                 spatial_dropout1d_165[0][0]      \n",
      "                                                                 spatial_dropout1d_167[0][0]      \n",
      "                                                                 spatial_dropout1d_169[0][0]      \n",
      "                                                                 spatial_dropout1d_171[0][0]      \n",
      "                                                                 spatial_dropout1d_173[0][0]      \n",
      "                                                                 spatial_dropout1d_175[0][0]      \n",
      "                                                                 spatial_dropout1d_177[0][0]      \n",
      "                                                                 spatial_dropout1d_179[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, None, 1)      46          add_98[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 596,836\n",
      "Trainable params: 596,836\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0085WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 0.0085 - val_loss: 0.0044\n",
      "Epoch 2/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0044WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 3/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0040WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 4/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0038WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 5/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0036WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 6/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0036WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 7/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0035WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 8/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0034WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 9/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0033WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 10/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 11/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 12/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0028WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 13/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0025WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 14/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0023WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 15/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0023WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 16/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0022WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 17/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0023WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 18/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0022WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 19/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0021WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 20/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0021WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 21/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0020WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 22/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0019WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 23/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0019WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 24/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0019WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0019 - val_loss: 0.0022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0021WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 26/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0020WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 27/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0019WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 28/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0020WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 29/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0020WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 30/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0019WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 31/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0017WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 32/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0019WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 33/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0018WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 34/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0019WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 35/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0019WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 28s 284ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 36/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0020WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 37/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0017WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 38/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0018WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 39/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0018WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 40/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0018WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 41/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0019WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 42/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0017WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 43/5000\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0019WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0019 - val_loss: 0.0020\n"
     ]
    }
   ],
   "source": [
    "pdict = {}\n",
    "\n",
    "# define parameters of the TCN architecture\n",
    "pdict['f']     = 45\n",
    "pdict['k']     = 15\n",
    "pdict['d']     = [1, 2, 4, 8, 16]\n",
    "pdict['s']     = 2\n",
    "\n",
    "# define parameters of the data\n",
    "pdict['bs']    = 20\n",
    "pdict['w_snr'] = 10\n",
    "pdict['w_len'] = 3*60\n",
    "pdict['cmpts'] = 'ZNE'\n",
    "\n",
    "# define parameters of preprocessing\n",
    "pdict['r_smp'] = 40\n",
    "pdict['f_low'] = 1\n",
    "pdict['f_hig'] = 10\n",
    "pdict['c_len'] = 2\n",
    "pdict['c_buf'] = 10\n",
    "pdict['c_shp'] = 'gauss'\n",
    "pdict['c_amp'] = 1\n",
    "\n",
    "\n",
    "# define parameters for training\n",
    "pdict['lr']    = 0.0001\n",
    "pdict['pat']   = 10\n",
    "t_step = 100\n",
    "v_step = 10\n",
    "\n",
    "# load the model\n",
    "model, model_name = load_custom_model(pdict)\n",
    "model.summary()\n",
    "\n",
    "# build the generators\n",
    "gen_trn = gen(cat_trn, pdict)\n",
    "gen_val = gen(cat_val, pdict)\n",
    "\n",
    "# TRAIN!\n",
    "my_hist = model.fit_generator(gen_trn, steps_per_epoch=t_step, epochs=5000,\n",
    "                                  validation_data=gen_val, validation_steps=v_step,\n",
    "                                  use_multiprocessing=True,\n",
    "                                  callbacks=get_callbacks(model_name, model_folder, log_folder),\n",
    "                                  workers = 8,\n",
    "                                  max_queue_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3MAAAEvCAYAAADvmpjfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd3gU1d7A8e/MtiSbSiokkNCbVBFRBKWDonjt5V7B3surgoiggKLYsXcUQVGxgEpHQDrSEzqB9N6zvc28f2yyyZKEZhCQ83keH9nZKWdmJzPnd6qkqiqCIAiCIAiCIAjCuUU+0wkQBEEQBEEQBEEQTp4I5gRBEARBEARBEM5BIpgTBEEQBEEQBEE4B4lgThAEQRAEQRAE4RwkgjlBEARBEARBEIRzkAjmBEEQBEEQBEEQzkHaxtqRJEkzgZFAoaqqFxxv/aioKDUpKamxDi8IgiAIgiAIgnBO2bZtW7GqqtGnun2jBXPAV8D7wNcnsnJSUhJbt25txMMLgiAIgiAIgiCcOyRJyvg72zdaM0tVVdcApY21P0EQBEE43dwe5UwnQRAEQRBOmegzJwiCIJyXNhwups1zi9mWIcohBUEQhHPTPxrMSZJ0nyRJWyVJ2lpUVPRPHloQBEEQ/Kw9VAzApiMimBMEQRDOTf9oMKeq6qeqqvZSVbVXdPQp9/MTBEEQhL9Nqvq/qqpnNB2CIAiCcKpEM0tBEAThvCRJx19HEARBEM5mjRbMSZI0F9gItJckKVuSpLsba9+CIAiCcLqIijlBEAThXNVoUxOoqnprY+1LEARBEE43CVE1JwiCIJzbRDNLQRAE4bwmKuYEQRCEc5UI5gRBEITzkugzJwiCIJzrRDAnCIIgnNdEnzlBEAThXCWCOUEQBOG85JuaQDS0FARBEM5RIpgTBEEQzk+inaUgCIJwjhPBnCAIgnBeE80sBUEQhHOVCOYEQRCE81JNM0tBEARBODeJYE4QBEEQBEEQBOEcJII5QRAE4bzk6zIn2lkKgiAI5ygRzAmCIAjnJQkxAIogCIJwbhPBnCAIgnBeE/VygiAIwrlKBHOCIAjCeel0zEzQbuJiXvx9b+PvWBAEQRDqIYI5QRAE4bzWmF3mnG6FL9alNd4OBUEQBOEYRDAnCIIgnJfeWn4QAFU0tBQEQRDOUSKYEwRBEARBEARBOAeJYE4QBEE4r9ldClml1jOdDEEQBEE4aSKYEwRBEM5rX6xLo99rq/AoJ9fcss2ERby+dL/v8z2ztjR20gRBEAThmEQwJwiCIAiAcpIjobgVlQ9WHfZ9XrGvsLGTJAiCIAjHJII5QRAEQQAO5JtOeduTrdUTBEEQhMYggjlBOI1UVUVtzHHPBUE4bUa+t67OssJK+wltO/6n5MZOjiAIgiAclwjmBOE0SS000/LZRVz7wfoznRRBEE7B4pQ8er/8BxtSi4+77rxt2f9AigRBEATBnwjmBKEBFoebfXmVp7z9ukNFAOzKrmisJAnnmO2ZZdhdnjOdDKEBgc0/J6Tj+DrLb/x4A1e+s5btmWUApOQc+2/4v59vrrNsf34lhSY7Lo/SOIkVBEEQhHqIYE4QGvDAnG2MeGctTrfIjAknL7PEynUfbuCFBXvOdFKEBmiDU+ssszrdbEkvY29epa+2TQW+XJ9G0viFLNiZw7pD/jV16+qpuRs+Yy29p/3B+J9S6j12pd3l14TT6nTzzopDuKuCP4vDTYXV5fv+r7RSksYvJLfcdtLnKQiCIPx7iWDuLFZospM0fiHztmad6aTUy+1RWL63AKvTzc/bsyk2O850khrVX2mlwKkPbCBJUmMmRzjHVNi8GfE9eaJm9lzy8eqa0SnLq4IpRVX5bM0RAB7/bif//aJuTVxDFuzMocfUZXUCwAGvr6b3y3/Q7rnFALy9/CBvrzjIzztyALh0+kq6TV3mW3/OpgwAtqSXnsJZCaeDxeFm93FqbQVBEE43EcydxY4UWYCzty/G/774i3u/3sr/vviLJ3/Yxc2fbKTU4jzTyWo0jr9ZI3esWM5kdzF23i6Sxi8UzfD+pRbtzgNAtLI7+0m6Et+/311Zt7butSUHyK3wHwjFZHfVWa8+bkWlzOrym48OoKTqWen0KLg9Cp+tTfN+rnruVBcGVDt62oQik4OSf1kB2rnmkW+3M/K9dVgc7jOdFEE4KyWNX0jS+IViILjTTARz57D5O3JOaKS1I0VmZm/K4N0/Dvktd7g9vkBiwc6cEy/xddnhz9fYeqQAgPSMdGIo43CRhZ4vLvetZnG4/TIbfx4soszipNBk58PVqefMH3dasTeoXpicVyeDVa2w0s63mzP9ln25Pr3edVVVpcvkZb4gvbLWPnPLbXy1Pq0RUi2caR9V1fD8nX6Xwj/D2GpGA98oSNr6a166TF5W7/KGHKuCv7qmT9JWMi/Zv9av25Rl/LIjm+rN5apSooumreDCl1acVBr+bQqthXXeI+PWjKPLrC6Nsv/jFU6uOuDtFy36RQrCseWcQvPwFXsL+Hn72VmZcbYRwdxZbN76PbSRsvkrrZSJ82v6XWxJ9/adeOL7nfR++Q+Sxi/0NcH5PTmXbRk1QdmfB4sY+OafTJq/m7eWH/QtTy00037iEiZNHg+Tw3j2u03c+PHGE0pX+YrXYdU0btd4MxLbAh7kr4CHfd8/MHsbZoebR6e8Qr+Xfge8/UFGz/yLMV/+xaPf7uC1JQdIyangYIGJ1ELzqV+kf8DOrHL25Fbw8LfbefL7nX7fqaqK3eXh7llbmfBLCnkVNQ+s3OIyWkveJlO1S27fq6fkv9pdX21h8m97ya84seHQBUH4+yS5/kIafdRKgtu+gqQ7sYIuXZM1yAH1N4tXVJWdWeX1NpvfdMS7f2ObVzlieJEVewt831XYXEz5ba8vaMmrsOFwN05tvqqqTJq/m+Ts8kbZ3z9pZ+FOBs0bxLs73mXO3jnsK9lHgaWAxWneZquP/vEoXWZ14fOUz33b5JnzmLZpGh6l4euXWmji+QW7WbAzh54vLmfzkZIG15UDspB0xZwj5ZL/Wg6Pg5m7Z+JWRA3p2Uojn3i3E0VRURSVe77eypM/7DqNqfr30J7pBAgNu+fQw3Q0ZNLaPps5mzJ56dou/HmwiNEz/6KblMpgzXbedN8EwMT5u5k4f7dv29GXJPJ7ch6DOsb4ll0gHeGpKVMJjk5kdmYTAnHyuu5TAPYG3AVA8U/34Ur+kaaSN3Px+5DVxGkrCdaqOEMTGTtzCb/o3wMJmkt59IqYi9vmvZFaSbkcUZuxZ+8uXpk6h5n6mfzm6cMrizvxyZ9HAJXk7DJujsqgpSaNa96vOdf06Vcd93q4PQqyJCEf56Ewf0cOAzvGEBqgO5HLXK/q2jiACb/UBNJ/7C/E4fbw/spU2saGkF5s8QuSl+zO54L4MF5fcoD3de8xRLONi+wfcOFLy9n/4ggAv/UBaucDqpteFZsdxIUF+K3n9ihoNaL85Vyhi9iILmIj1iNPnumkCCdJYzyI6glAa/S2ZtAE5KDqSvFY2xxzu4DYRQCY9k0HyQFoQPW+ZvfkVvqmKXEeVZMT3G4yjuKBSJI3yLjn661+38uS5AsYXl60n20ZZb7vUgtNtIkJ8X3+3xebGdU9nhsuTPDbh83pIVCv8Vv2zeZMZm/KYPamDN8z+PqPNrAto4w/nrqc1tHBxzzf0yZ/NwTHeP+rh6Iq/G/x/wD8grXaVmevBuCd7e/gdmvRajy8s8NbAxukC+LRHo/i9DhxKS7CDGGw+VOU0AQGz/Je6K83ZoBsY/amNHq3bFJvH2hjyw8AULn12OejKFByCKLbH/fU/djKYelzMGgShMQdd/X5e9fz0YpS5t49jCZGvW/5/32/k6GdYhnRpenJHf8c8VnyZ3yS/Amh+lBuaHfDmU6OUIuuyVoURxwSg054m8Fv/UluhRjo6WSIYO4sZg4qYLtq4DD/Y5/SgoHP5rLS8DTptfL4Mgq/eC4jVU1AQiECM/drf6PiLyMaz+Vs3JbFEv1bdJCrSoNVoBCmBNR7SKJSPoVa76yRy6/w+36poebfM9oeAKAHLdiUnsX3QeNwShLhHgVjVc7jas0mrt7ch73yeGbrp1edGKCDw0oztqgdTvh6tHluMQM7xDBzzEUNrrPpSAlPfL+TVlFGVj59RYPr1eeHrVkUVtp5ZGBbBryxusH1bv9sM1trZaZqm/Lb3pr9BWwD4BP921znnEqvl5azqp40bTpSwt68SjYdLqHI5G2W+uqS/cy++2K++yuTIZ1iSSu2cMPHG5l7bx8uaR15UudV2/K9BaxPLWbyNZ1PeR9ni9RCM2sOFvHfPonotTVBbpHJQXSIod5tFEXF7HT/rUC/IRPnp3BJqyiu6urNMAXELaj6pv5i+7RiCwatTLPwwEZPi3DyNMF78ViTQAkgqMVMADzWRAACE74BqoK0hrY31hTSTNd+yrS2Rwh0BFN4ZGKddV9bcgBt6A4MMYuwpD6LpLH7AsF69y1LlFlrmvwt3VNTczf4rTVMuaYzn/x5mEC9hsNFFtYeKvYL5jYdKeGWTzcRYtBicrjZPGEQsaEBfgWA4G31UR0oDnrzT5Y+0Z/2cSF8vyWTVtHBXJTUpME01lZkcvDCr7t57YZuBBuOk81QFFA9oNFRUFrB0t153LGyLxhC4cH1IGvBGA0LHoF2Q+HHuygc/esJpaPaB8lv+n2euXsmM3fP9H2eePFEbl48FhkI41McTRci6crRGtNYaYpj3raZ3NSrec0O8neDpeiYx1x3qJj/frGZ4Z3j+LjlGlgxGa5+Fy4cXf8G5Vnwwx1w93KYFguyDtxVGdqdc2ByAwOt5GyD8EQwRjFpywMQBuMXBPPpbQN8q/yyI4dfduScUKFpY7C7POg08knVxqCq8Nvj0PVmSOp7Usczu7yte+zuv9Gixe0AVQFdA8/jzE0Q0wkCQmuWuexQkQ1RbaBwP0QkNrz9eSogdiEAsvSAb1m51cmqA4X8p0dCvdscqVWYfjJUVeXb/d8SYYjggqgLaBHa4pT2cy4SwdwZ9uX6NGZtSGf12AF1vruraSwAyWmZdJQzWWl42vddnkZDuk5Lf2UJHuOfdLc76G+zc0Cno5nbjQ4Yp/6Am8ZvS1smy2wI9I8G+yQ19/u8Od0bPAaqKhLUBHLAuxFhrA8MYF7uVJLs3/ptpygq983eRqtoI+tTixk/rC39koy4tEYAcg9sRS2LQZX1yG4rRCTB7/8Hw18BvZElu/OBYz8MyixOZEmi1OokLFBHeKCOeduyeKZqCPE3llVnylRkVJSjrmBDgVxDesreZpXFZme9/Wwe/25nnWVHiizsza1k/M8pfLk+nSGdvPfC+tRiv2BOVVU+XXOEa7o3o2lYIA63h/wKO4mRRr/92V0eAnQa7q0q8c8us/H56F4ndR71sbs8ZJdZiQsLRKeRMGg1x9/ob3C4PWSUWGkXG8KwGWvwKCpfrEvDaNDw1k3dOZBv4ql5u5j/cF+6Nw+vs/17K1N5e8VBtk4cTFRwTcDnUVRkyX8E0qxSK6mFZgZ08K8dSMmu4Putmbw46gK/9edsymTOpkyu6uqfYZI09d+L1QUG1Rmst5cf5PL20fRsEXFyF0U4YRU2F0a9hgMFJlpG+f+NBDX/GgB7/sgGt9dHrqav2U2pOxarEsEhNR6Q0IZtI7DZPN962ogtQCQ2g5nQ0E3YtC5c5b3RhW1FdYVTYe5McPNfkDROkI/VL0slScon3dTUV9BTn09/XU0FwXiwESapVKhhLNiZQ3x4IBfEh3HvLO/fvamquffmtFJGHlVLk1poqmpq7wHJBaqBYTPWMLRTLMuqmn2mThvBkWILqw8Ucm+/Vr77P7vMymWvruK9W3vQo0U4H/95mEUp+fRpFcnIrs34cFUq40d0oMDkYP6OHB4e0AZWvgRrXod2w+HgEgBigTuqE+SohBlH9X1L/g6Aym+vh4TGq2V6afNLDJclZkSEc7HuOTYG1mTINQH5vLjnSq7tugm9vuqe+bgq2GjpzSwWm+28tfwAk0Z28j0D//vFZppSyBbXBB5LNvMuwG+P8eCON0jQR/Bck14w7GX49VE4/AdYq5pzvlj1fD+6yWB+CsTVuh4lh2H3z7DqJe/nF2qayu4t3gMMYFdWOZ79i+kolZGrRnr3oarQtKt3RVWF5ZOg5xhvQFK9LGM9hMZDk5bezz/dA7t/hE7Xwk2zvOu9fxFcdA9cfD8cWAJNu0Go9zfpMGkJo7o3453yxyA/GSbkwpJnod+ToAvy1rgW7genGeK6es/9x7sgcwNsnwXP5kDudm8gn3ip/3VYOQ1kDfR7GpwmCIxALfa+s4tzt4I2BgIjIGMdrJjMAZ2O78IjiL9gKi+vtPLmoA4Mi63gZ08pA1sMpFlwM+9+3+oE1mIYswh2zIZdc6HDSNj/O1zxLKx+pSYN2kC44HpvkF2foS95r01JKkS2BV2t/FJFDrzdCW6aDR2vrjtSmikf9aO+SNaq0W+jO8AdC06oZraO6ur8xhpZW/HAoeXQbljdfTot3nOLblfvprXfld2nLkdGoWdCCInRYcc9rNlp5sVNL9I2oi3DEocRHdiMDpOW8M4t3RnVPd633s6inUz/q/4Ct8SQJDJM6Xw1/CsujL3wBE723CKdqUEoevXqpW7duvX4K/7LJY33llrUKTErz6LLgisBiHW7+TqvgKmRTRhktTI16sRqZhZn5TCiufdGH1tSxh2VJgD+CAqkTCOz3RDAlOISTraOokvLkyvt+Ck7j3KNzN1VwWm1BJeLfYdfAVVPfHgg68cPpMLmotsUb8AzSN7GJO0ckuQCMonFpci0lvP8d97vKVjrLXXdf8tGbvoui0q79yVYfU3tLg8Lk/MYdkEcwQat75pXu79/Kz6pGna8tl/0z9NDTvULOCVtBaqiAyUIA04MuKjEP1OoCd6PYksgTXefb9nRQauXiqSxoHrqb8rUW9pHlFTBIqWPb9lDV7Rm3HBvbeaag0VszSjzDWwTHx5Iz8QIftuVy96pw6i0uTlSZOaLdWn8sb+QeQ9c4tcv8s6+SUy8qhMFlXYGvrma+Q/3pUNcTamjy6NwIN/EBfFh5JbbiAzW+wVrqqrS8tlFdJbSuEazAUUfyr133oM2PAH0wbB4HOz8Bp7L5+MNuczfkcOSJ/rXOc/VBwppFxtCs/BAssusfL0xgwlXdqz3mjzzYzLfb83ir+cG0XvaH37fXdE+miZGPT9vz+H1G7pyY6/mdbYf9vYaDhSY+PGBS5j7VxbPX90JRVHp8eJyJl7VkXv6taLE7MCjqvR/bRV2l1KnNrTLC0sxOdwkTx5KaIAOVVWZtnAfn6/zDlyz8qnLaRUd7BuEwXxoApOG9+Guy1r6paX6Ptw7dRjXvL/e13f0szt60Sw8gNRCMxpZotjkoHuLCF9wml9hJybE4Nfc+PkFuxnWOY6+baLqvW5HK7c6CQ3Q8cmaI/yVVsKqA0WsfOpyjhRZGNwptt5tdmSW0So6mKV78ll7qJj3bu2BoqjsyCqjS3w4983eisuj8M09fVBVlZX7CxnQPsaXTqdb4Uix2e8eq37/SJJEoclOpNGALEGlzc22zFL6tY1Gp5FxeRRsLk+DNaoOt4esUhttYrx/SzuzyvlxWxZPDWlPkdmBqkKraCNtn1vM1d2a8duuXPq2iSRZd2+dfSnOJsh6bzNzvTUWZ1BBnXUAUtIyuScuhhFmC5Ojj/9M7l8Ja0LrLo9JHU1hm1n+C3OvQYlZSZvypiww/cFN7qcoU0NxaFxkOjsRrsklQbEyWrOCG7VrAMhUokmQi+jWsgUeezPC0m5nhOYvKgniR8/lfrs3tpmOrCvHfPA5WimVBODEamxOmllLQvN3qQjOJc4Jh9KmgFJT6DGoYxSrjuxGccQx/bou3NSrOV2nLEOrkXzTOAA0DQsgr8JOkpRHj8QofknXcUF8KLtzKkmQilhneNy3bqFGQ7CiEHSMvEiJLBOqKCQbDJhkmUfjoo97vU9WG6eTVL2+we9fKiph1JPZ8OUIzNmbydNqua4qoDTtmwZoeO2GrtzUqzl2l4cOL/zMsObPsiHIGxguzMqlhdvte38+WFbBRxFhrM3IJlxRcAMzmoQzpqKSnVXnWaLRcKXFQrPafSS73Qo9R8OXw/3S50zsz4VyOgDWrDEcnvgUSeMXkh5wGxsDDFhkmcHWWk3X+o8Fayls/cL7ubrmL+VH+OluHoiNZn1QICsyc4j11Dq+Rg+eWgUQkytgclWGPP5CiGwDyd8f+2LfuaQm/W2GQOryhtftciNc8ggZhrY0kSoJebeqNY8+hEU6DyEt+rKuYCvfhnmbGu9MyyRDpyXJ5UbmxPIrjwR3oEPqGlq7XFgkGass0cNx8iNz52o1hHoUguu7l1teDv/9Gd7rAeVVg6U16wH3/AGvJHiv3SUPw9xb6m6rDUS9eym/7simk5xJ28F3g1bvrRVUPN7awKObJK+YAuve8l7fm2d7141sA8smwsb34bZ5NdvlJUNZOmRvgYI9gAqP7YA986HrTd6Cldwd8PUo3+4/cl/N6DH3EzRnJIQ0A1Ou94unDkBwLNgrKHZoGLDAG4wvunozeq1MbGgASeMXslg/no5yJoVPFRAT4l85UDuPFtDsO3Rh/gXenw74gTE/vouqGPj25v/jzpUNF8DVJ2V0/XN/nkmSJG1TVfWUS9hFMPdPsleCRudXDd96/K+8o/uAkZpNvhJK8w1zCfrxVrqdZNB0Ijo5HOw1+DdBa+9w8h+zmVi3h1YuFzMiwnmzsLhOkPdNaDCZWp3vodkYFHcIlkPPAZAQEcjwznF8vi4NA04OBIw56f1d5XiZvWoL9hvGsC5oML0enU23qcvpIR3CpA3n0euH8Ph3O2lCJRsNj2CQ3NztfIo/lAtpL2VykXyAXz2XoCCzO+AeoCYQGxr+JRubepuWmvZN50vjWPaGmHk//y1sBKKPXoYhaqUvLV/mFXB3XAyX2ewsL3yMV6VvmGa/D61sJVhXREHSLwBYjzxGO6eLUKxsUduj4q0TTA+4ze/4AEa9BqNBy2s3dGXMl1sAuFzexWG1KXdplvCS+78oyFzZJY5FKfnHvV7dm4ezM6umRLd2ocIbv23ls/VZDO6SyMKUPLomhPHzjdE8/F0yt424AuwVXP7z8Uu4yqUwLrG9jY0A1o8fyN7cSoZ0iuXpebsITlvKyrIoMtVYLm8XTcWhjTyi/QX97XPp36Epn605QpnVyTebM5lyTWeeqBqAplWUkbRiE1FUUoR/DZwBJy2lfH6Zch9fbUjn1SX7GTusPa8vPYAkUWewgrdu6saTP+wiPEjH3Hv7MOKdtXXOQa+RWfJEP1pGGWn5rLc53Ns3d6NH8wjSSizcWfVb1BbScTwA5kPjUd3h/PTgpVyYWFPrljT+dxbqJ/C462FS1fqbm9T2+6OXMfK9db7Pl7aOpFdiBP83pJ0vTdW/34q9BbSKNhKo17B8bwE/bsvmvv6taBcbgs3pYVRV362GjBvenpaRRnLKbby0cB89WoSzI/PEBsloHW3kcFFNbeSbN3ZjZ1Y5s6sGaao2994+3PrZJgB2Pj+E7lOXM7hjLBcmRvDqEu8w/l3iw/hidC+em7+b5XsL2PjsQJqG1W3G9OQPO/l5ew6bJwzi8e92+AYUqe3o6wc1v9GpeKugiCdjTzyouMJiZbUxqM7yaLebIm3DjWTeyy/yC14SKuLJDvMOrJSSlsldcTFsCQwgJS2TR2OifMdYl5FFqUZDS5ebm13PsLfdXFRFgy37fwS1+Mq3v8lFJVxvrvm9amd+O2f2I8jWlJVqF1A1hHScAMC9eUZGWst4zj2G3Mi9ZJRcA0oQkq4U1RWOJugIYY4gtuu8rUmqn2Gr9P9HvFxAoVZDQlWA0qVlCzo7HMzJLWCfXk8Xp38m2gX0PA3vwlOxPS0THXUDhKQDd5GitOPmXs159YauPPT9Utban/Zb5738IjYFBvDNKbw/U9L8R0rO03gL1aqDYA0wL8ToK+itHcxdmfg4a6sCynUZWYQda1jVuK5srSzhjwALc8LqljykpGVyUKfj+egmlMsafsjNI7TW/spkGYOqHjMwPxYV+DMwkN52OzsDDCS5XL5Atq39a1ICR7PYGESC202AonJb/LFrqxr6mztRI80WBlqs9Lbb0amQrtOyMNjI12GhXGyzc4PJzLyQYO4vr6Cbw0GvJO99sSE9i5ATuAbpWi1GVSG6ntFQNwcYsEkyV9i8AbhFkuiT1JyHysq5q6ISQ9sRcHCxb31X4uWU2PIoLU+jk/PEpk053aySxMVVrbaqm6inT7+KDu/eji4smZS0TJLs33Jvv5YcKDDz5o3diA4xkDR+IZfJKbSU8pjfbuWxDnFKRDDXiM6bYM5h8nZiDm9eU3oFcM37sPgZcNXfBGtpUCBPn0RG4XSIdHt4qLyCkWYLn4eH8ln48avDT0VKWibXOF5EiwcdHj7Rv0W45H9dimWZLJ2WR2Kj6W+zM7WoBJck+V4ae/U68rRaBlmP3Wn2Yvv7bA54BIcEWhWq65nGOMfxlf41crQaYtweXyBbrJEZ63iY4ZpNvNSqpoT+m8Mankh0UKTVsiYjmx7WOX8rYxjl9rAqy5tBO6w0ZZDzzVrB3DdcKB3kJ8MUXnCNZopuFtuUtuxXWnC71r926g3XjaSorfhT6QZAKBY0eEiQiklRWwHQWsrhD8NYv+0sqoGP3Negu+Ip5D+n01wq5FrNBgCWeC5iuGYLRWoY0ZK39Hax5yJGaOoGMLNCQ+hltxPn9tBEUWp3v2Ss6z5e133KJNcYntL9SDj+o5i2sX/NSv1TtJCL+No9hEuamFhXGsY77uu4WbOanzz9KcZ7D/6un8AFVaXQ1zheJFltDUATKtke4G2bP9jxGtFSBTIKG5XOKMgE4KCDlEW8VMxSpRdutIRi5go5mWDJxhqlC9lq/YMuBMpuVMVDBGasGKggmC7SETQoBEhODinxJEoFXK7ZxV4lkQ3tfwZALbkYc+F/AO+LrNBk582lB1lkuZ32Dic/5ubXW3Mro9BX3k2lGkSQ5KBQDSdbjWaUZj0hWPnC4w3cxg5rT+mKt5CQXvIAACAASURBVHChZW3oVdwUspsZma2IkcooUsOxU3//wYbocKMC7qpW+AlSEU2o5DbNH3zmuYrDajxNqKSpVMoeNQkdbrpIR9ijJtFdOsxmtSMyiq9Qovb5dJdSyVRj6SEfYpfSGh1uJEllinYWgzQ7+K/zWebovc2ZPnBfw7vu63CgJ44Sbtas5jflEl6+9zqySq3szCrnUHY+/dtG88bqnJM6RwAkJyEdnj/57U5RostFhq7x+2pWu7O8ki/DazLgsW43BVotD5eVc0CvZ8UxMrVtnU4ONVAr9VRJGW9GRpBgDSI7yNrgPmRzS5TgNFSP3tt8FJiVW0BPh4OVnu5crN2FXlV9gdkneYU09bi5JsHbzO2e8go+Dw/jjYIihtV6jo+LjmRxsLHuAc+QVZnZDGjhX/iyMCuX/mZvM90Pb+/JM9uHNvpxN6ZncUlS3dYGAC8XFTMhuqZWXnE2wZL2KIHNvkcb4j+/4euFxXR2OGheFSS58AZR1b/+0ObNyDtG4cLRmrtcaFS4wWTmjciawqqFWbmYZIkWLjcWWSZEqelLn2zQc3uzOL7NyccqSxRpNFxpsdZbgD3CbCFdp2OfoeFa07NRSlomWwMMdLM7fPkJuySRbNDT3OUm2uOhx1Hn+3BZOWZZZlatQHpbWiZlGg3jYiLZHnBUDZbTRZLLRYrBwIV2O8tq/Z2sysgmSqmas1KWsMgycW7PPzqEvU2S6F11z1rT78dja8lfEwYx6BfvuAcpaZkcqapF/dA9ike03n7mNzkm8YPhRVYGBfL4acgHi2CuEf3rgzlFgS2fw+KqTHNMZyjc4/u6Qpa5LLHmhfB9Th4xbg+rjIEn3Izy32ZmXgERHoU2Lm+p0s/BRgZbrYQqaoNNJR4uK2eQxeZr7lK7BLNclumXmEAzl5ul2bl+23Vp2YJrTGamFZfWWX+42cJD5RW+TAYcuxT+GpOZgJLe/JC0t97vT9SneQV0crp4MiaKB8sruLOqWerXhzV0k9P4KDyMMRWVvhciwE6Dnli3h6ae4w9VrgKrggK5wmojxaCnQpZ5OC6GpVk5NHN7cAHL5XZ83rSSD/OLiDuBfabpvC/9CdGRxLvcLD0q0/VDTh4ToyKZUlxKgVZz3GD7VFXIEkuMRm4ymfkhJJg+NjuJ7lMbpnqRpzeBOHjHfT2v6z6hrewNFFyADvAA2VotD1qmssgwwW9bhwQ5Wi2tXG6/e9ae+n+4XDXNFyVdMcFt3gDgi7wCetsdvvWNRX14seIwQzTbTin99Vnv6Uw7OZvxrnv4Qu9tlnydYzJt5RxWe7rRT78B1RNMC6mYx7U/17sPD5Cv1RBfq8nX2+5r6SqlMUizC7skoVNVcrRaKmSZdg4VneRiga4lP2g7Mde2sN79noqL7N5RBLdUTYkyyjGVLDWKZQFPEUXNPeZQdcz2DGaR52J+NkymXDXyhvsmOutSsOkreTteTAFyum1Mz2JY82ZUak68P+3m9CyytFqO6HWMizmxpsNnmvnQs6juEED+WwV7jcbcEoIbnrO0pdNFmr6mcCFIUXi5qIQnTmMh8p8Z2cwNDeHjiNNTMHy2inG7KTyJAPl0mpeTR4daNXdmScKgqvV2t9kUYODVyAheLSxhS6ABWYVbTWYqZQmjonK8v+h8jYYhLWr6tFXXzh399/F/pWXcVWHyW+aQ8NV0NjYRzDWif2Uw9+ujsP1rb3v27d4+ECqwy6DHLUl4gDytloFWK0Obx2ORxTDz9Yl0eyg5xYE0VmVkMyCxbpO1Z4tLucVkRgWctUqLghUFsyxzsc3O5sAGhvg8C/S0232lcgkuF4uy85Coae4zwmzh4bIKRjZvxtUmC4+WlfNnUCDToryjz/W12lgf1PAoW2syshnevBnWWvfkw2Xl7NXrGVNhYp9Bx7UmC5clJjC+pIyedgcBqsKVzeMb3Gd9UtIy+S04iCBF5SK7nW9CQxhusZLocmOSJWaFhZLgctPG5WJM01gmlJSyX6/n/vIK5oWE0NbppI/NTpCq4pAklhmDmNRAf6XktEzKZJkIReGZqtL9xVk5BCoqH0aE8UNoCM+UlDHAaiXe7UEF3mwSjgKMKy3ni7AQZjRpeDCS+dm5tHK52WnQY5ck7mtaf1+zanH7H+GQmoABJ/qOx64RinG7iXN7+Dy/EBX8mi3ZJQm96q3zqj4/gAN6Hc1dboJUlfWBASQb9NxRYWK/Xo8OlRSDnk4OJ1sCAlgQYiTMo/B0aTl7DHpei4zgvrIKHi6vYFJUE8ZUmGhbVaiyy6Dn1SYRpAR4a/gut9p4uqQMtyTxn1MYhOK1wmISq0rzn49uwitFJbRy1QTe70SE0cvuoK/Njop3cN1SWaaJUrcp0pYAA3c1jSXc46G8Kli4udJEgsuNW5K42Gani9PJPr2OQEVlZngov4ScoeH2BUEQzgKzc/PJ0mqZUKug5D8mM38GBVJ6goUuw80Wbqs0MS4mivxagerNlSaeKi335bGOpjiikA3FdZZ/llfAd6EhRHk8fB/aeF156iOCuWMnZDjwDt6Wa5+rqtrwGM78S4K58sy6o20Bc0JDeDVSjEgnCIK/XjY7d1VU8lBc/U05j6W64OF89kRp2TEDbEEQBEE4ln9jMNco9b6SJGmAD4AhQDawRZKkX1VV/Xvtzs4mHjfql8NJL9hBmEchR6v1dr49SzpmC4Jw9tsaGMDWU6wBPt8DOUAEcoIgCIJwlMZqxNsbSFVV9QiAJEnfAaOAcyqYe+O7BzhcuQcZkFSJWGcmh3U6tlVnvnRArX5UgiAIgiAIgiAIZ0pjBXPxQFatz9nAxUevJEnSfcB9AC1anH01Wtnmw+zXlOLtmSGRogs64fbDgiAIgiAIgiAI/6TGCubqm16+Tmc8VVU/BT4Fb5+5Rjp2o5lxTz0TV6oq+SUlOH68m6Lyjb4RBgVBEARBEARBEM6kxgrmsoHaQ9ckALkNrHtukSTioqLggQUkAikAHhdIGtQ32iBZSwCq5mUCS9Xw9oIgCIIgCIIgCKdTY/Wo3wK0lSSppSRJeuAW4NdG2vfZR6MDWUYadwQmV8DkCqSnDqIDwhWFlLRMUtIymZeTx3c5eczLyWNmXs2E07cdNZ+GcPpdX2km3nVq846dDZrVSnsPu51vc/KZnZvvW9bR4eSn7DxuqzCxIDuXlLRM+thOfE63eTl5jCmvPOY6X+V67+FARWFyUQmPl5af5Fl4J6z9tWrOv+srzSzIzuWGShP/V1rGuowsrrBYaXLU/HbJaZn8t6Imbd/meM/7g/xCXi+sO8RxtYfKynm9sJh1GdncW17hW/7KUdv0tdrYnJ5FSlomX1b9nV5j8p/QvD7f5uTzQ04eekWlt+3485VZ9r3MqIOD0O979rjrAnSxO3z/XpSVy/a0TH7PymVScSnJaZlsSc/invIKdqVlsiIzhwXZuSSnZbI+o6bF+9MlZTxUVv/v1MPun+a2TifXV5oxKAofV13b5LTMerf/Liefpqc4jx/AA2UVvt/h6ZIy3igo4sfsPF4rLGagxcprhcW+52hKWiZ/ZOawPDPHb1ntOSWHWPwnsx5c9bn6vrmj4tj3tiAIwvmk9vP76Ofn3/VSUQkdHM56v2u3/456l/ez2vggv5AZBUWNmpbzRWNOTXAlMAPv1AQzVVWddqz1/xVTExxNVb3/yTK4bDAtrsFVd+v13Bpf830Hh5MrLRY+DA/Dfh6OWne1ycJvId4Jp1PSMknXarm6ec1gM7Xnkaqtk8PBnRUmxlbNl5KSlsnckGCutFgIVVS+Dg2hTCPzRJk3M1+o0SCjEuXxn7PqtSbhzA4L9X1u5XRxpNaEqp0cDvYaDPWmvanbTV4jTAi6LDOHvQZ9nUlbl2fmEOXxMD0ygnvKK/0m815kDGKfXs9jZeV1Jv10AVOimrDCGMR7BUUc1um42mzBqKqMq5p3DWBLehYBVc+BQo2GQS3ifRNZg7fWWcH7h52v0RDp8fiOVSFLBCsq3Vu24OZKk29+mLvKK2jvdPFM1e8yJzefrg5nve2x63NAr0OvqrSsCmLVqmPXNzl6qSzjlCTWBwZwvdnCgmAjfW22Or/x0ar3VF+v2M/cV9JPTqGpNhuDiu/62CSJLQEG2jpdddJilSS0qoq+6nPtScMNaaMptnf0fQ4OX4fU9Hff5/nZuZhkmZcjmzC5uIROtSZ1bQwuVUKWvHPTXRs8hBmOVbR0uRnjHEc7KZ1LQ3+jl91OcAPvg0KNhmKNXCddE6IiWWkMrHfOzJS0TOYHG+ljsxPp8WCXJJIDDCS6XCS4jz8h/bGUqcFc7PiAIfI2xmq/J0kuoFgjk6rT0adWEFyfVKUZbWRvgUIXMRrxWWltRja/hBh56xwbvfSOcjNmDfx8FsxlaMv+L4EJc05qm6FmC8uq3gunw8U2O0MtVl6smv9U+OfNKCjCKUmMsFh977LwWnN45mg1LDQaCVRVEl0uAlWVcI9CiKKQr9Wwx6Cni8NJ16pgLV+joVCroVXVu6H6HVIiy1xRTys1077pdSYN35mW6fcedgOFWg3DTnIe2xP1b5yaQEwa/k+aHFZn0ZYAA/NCgnm5qMSvzevqwEAejYuus/6/UUpaJhfb32eB8XGKZA1dXE6KNDIDWyRwsc3O5/mFlMkyB/U6fg32PmSGWqwUajSMPMkSpaWeXgzTNHzfpem0OCSJdk4Xn4aH0s9qx+6M5nNlCOtar/St935+IblaLS9HNWFpVg4DzF+gxYW2w1QU6URDlhrf5uTTxel9ODok+D/tVeTEbOeIXseFB27hK/1rAOxVEukkZwBwq/M55urrLzMZ5HidF7VfkigXsEnpRIYSi15yMdM9gu0BDwAwIyKML8LDfDUcGz2d2DFoNrOXbKCjnMFM/RsNpnef0oKOcmad5a83CedCu4OBVm+toEmSUCQIU1QOK03ZqbbhUnkP0ZSjlfyDrbudT7FB6UxfeQ9blPY8OqAVg9bfTku5gImuOylRQylQI5BQaSvnMF33uW/bKxxvstrwVIPpTbJ/C0AElXyoe5dLNN6BdjOVaIY6X6OHnMqdmiX85OnHPjWRTDUWUOkhpbJDbUNP6RA2DGSosfSQDzFc3sJPnv7kqFH0k5N5S/+xLx3L9ePQSR5foNDb4uaPTO+1nH5dF6Yv2U+5zUpIh0mAd8L2e20TCZWsrFG60lU6AkCGGksX+QirlR70lA5STBiZagxf66azQ23Dz55+aFDIV5vwtX468z19yVRj2Kh0xuV7mqjoceNERzspi0NqPOoxG2So9JeTWaN0paWUz1XyJq7XrCFZbc0ozQZ+8lzGC64xmAnyrS+hompsyPpipga9jtEWw6dSf/ZZrgAgFAuVBNEEE8sM44iS/GvJ3neP4hHtAgD+8PRgkGaH77u57gHcql3l+7zI05sfPJezWunhtw8dbhQkRsnrSVFbcUj1ZiKGyX9xUG1OmtqUy+QUstRoMtSaQrSjMxXnui/zCk6qX/ftFSYeLC+nRKNhVD0jNce73OTo6i+oGmixstIY5Pv8XHEp06oy6a8XFtPC5WJSVCQHDXqusFhZfdS6t1TVfmdpNZRpNBzQ69gaEMCk4lK/QoWzLeDuZnewK8C/YO/5AgvjSt/h2m5xZJba2FW5msBm8xrtmI+UlfN+RPhJbWM++BzGti8jSf55vFi3mxVZuSjAhOhIFgYb6eRw8G5BMbEez0ld70EWK38Yg7i7vIIRZivTIyP8pl6ZmVfARXYH6Vot8W63rxCwUpbom+jtmbMqIxsdKmGKylehIbz5L5ij962CIoZYbb7zmVpUQh+bnaEtaoKTB8oq+Diibp7waD/m5LFXr+f56MgG13mstJx3m9S9P1LSMnk3IozPwr3H2ZyeRdA/mOc/pNNxXUJTAOJcCrmpk3l0RE8+SL8WgGtNZl4sLm1w+9P1ty+CuUZ0XgZz+34DQyjEdQFtAHw5HPJ21btq+RnsexfiUbDIElvSs/BIEjlaLVEeD9sCDHVqjRqDfd9Lvsxnr8QIUjIKiKKCl5qMp6fdQZhy7BqWo1lVA0GSt3TeNmAqlyyOpYlkQo+b/ar34RBNOVsCHgLgE/dVvOK+jSgq2RrwIAA97B+zoyroqQ4EEsKXUNF0NeAtXUoLuA2HJNHH9jHleGukhupWsrHNMgC/mqph6RfyH2kj01xjkGQblwau4bum3v6WgWUX8EyJies1a0myf0P1eEJ7A2/HKkn0ss6hlZTLaM1SJrtH01LKx4mW6wf25f/WXwRAO/ssOkkZDNds4XP3lTgMkZgcDTeDM+DEhRblqIx9yuShdJnsTX+X+DBScrw1mhFUokGlGO9LIY4SVl9tJWD5M8f9Pea5+/N99CNYCWLqqM70SmrCoDdXc7jIggYPraVcvyBjeOc4HhnYhgviw0gav7DefV4QH0pF7iF+0L9IP8cM3GiJ0jsxOcGDTJKUz61D+/Ltsg240ZChxrFh/ECu+3AD+ZV2rgw+yApzSy5sFcfGIyXHPQeAwR1jWLGv0Pd51l29GT3zLwASpCLK1GAsBKLDjYyCvuPzALgqu2DPuR2A9OlXYXd5yCm3ce2iS0h0ufgqy0Ivx8cnlAaA1tFGDhdZCDZo+fmhS/EoKiPeWQvAK9d1ITEyiNs+2wzAiicvZ/Bbf/q2fXJIOyKMeibN333MY3SIC0GnkX2//98xdlh7ftqWzZFiCwAXJhgpzznIYbUmY7PkiX4Mn7GWIZ1iefSSKDbMeo433DfhRsuEKzvw8qL9vnUfvKI1H60+jCTBk4PbkRhl5LG53gBw4lUdeWnhPgCahQWQW3Hs5q//VDB3faWZ+8sr/DJz1S622SnQaEjXH123XuPLvAJmhYb4BUSyqvoVHC3IziXO7WFAi3jaFHSnTfAGnikpI0hVedP1H75qt8233oyQeFaFSuxKT/c9AZ6NjuT3o2pldPueQY5cjyNmHQDO1Cfo7K6kmDAq9ZV4Wn3hW3dowQMsD1iLyxVFu+K2LDA8jwtwSxJ7PW1Y5LmYckMlMeFrGFdafsK19CZJ4tKk5sdf8R8wuqKSMRWVDGjh/2427ZtO2itXIlX9HknjFzbqvZWSlskevY5b4psywmxhelEJOVotCpBY1VzuN2MQE6paQljT7+OHMbdz2+e/oG8zw29fT5eUMbqy4a4eTmBirZYb29My6VmVqf48r4BFwUZ+DgmmjdPJLzn5dbYt0GpYYjTyH5OZqGO8u29rGkuQqvJ5fqHf8nWBAXRxOFhmDGJqVCSjTGZGWKw8FxVJibZuO4pP8wq4r1YBxkNl5VxhtXFTfNMGj30ixpeUcrXZwobAQF/Ln6P1stl5qbiE9YGBfBUWQqUsU6HR+ApI3cBiYxBXWaxIwLTICL4PDeGT/EIutdlxAYoEhlrZ8A/Dw/ioKsir/VuZJIlb4uPI1HmfE7WbmQPc6RzL08EzMCoqDkki0uM55vX/p1QHZKZ90+nWPJwFD/el5aRZzA4ex2U2O9tj/kP4yKlc++FGkgPuA6C9/SuaSSXIxoMUNl/c6GkSwVwjOi+DuaM5LXw79XY+9Yzk1uEDuP/y1r6vtv/2MaNLPzjlXT9RWlbvBLsf5ReiUb3Z5ncjwrmropJwj0JHp5M8rYZWLvcxX7I5Wg3DT7Lq+6P8Qh6Mi6n3O0fRIJzFQwjSa9g7dTgVNhfdpniDifSA2wB43XUTY3U/UKyG1inVP9pNwV/xV7G3oVv69KsAfAHBmEuTeH5kJ1pNWATAsocv4vEPf2SfmsiwzrEs3VNAzSCsEjsN9xIuWXzBHIAckI1ibwbIxFBGsGTjiOpfoi3pSlHdoaQb7iBPo8GoKnS1flMnrfGBO6lM+g7T/qmg6ut8X58Pb+/JlV1qXlJDn/2YplIpzz72CPd+vZVikxOby8NXd17EmC+3ABAWqKPC5uLGCxOYty3bb39f3nkR439KZtFj/bC5PCREBFFudTL2x2Reu74r2zLKuOfrrax4sj+xoQEY9Vpmrk9jVPd4Io165Kn+pYF5g97BmNCNgbMLucUxj6d182BCHuiD/NbbkFrMC7/u4fv7L6Hni8t54PLW9G4ZwaT5e1g99gp0Gm8WU1VV2j63mIlXdeS35Dy2ZZQBsOuFob77pNqo7s3o2DSU6Yv38+WdFzGgfQwuj0J2mY0yq5OeLSKYtnAvn61NI2XyUEICvC9Fp1vhoW+289TQdvywNYsHLm9NgE7DrqxyMkqt/K9PIgBFJgf/+2IzBwpMqCqsGTuA15cd4Ldd3iZ7AzvEMHPMRWw8XMKtn23yZebMB59jw7hRuNwqLSJrrkObKe/ygLKBP4NuJaWspvbjnstaclHLJtw/25v57tsmkvWp3oBzxs3dGdW9GdOX7Ofa7vF0bOptGnzrp5vYeKSE1Gkj0GpkZm1I5/J20SRFGZmzKYOJ83cTYtCSMmUYfx4sYvTMv9BrZFKmDEUjSaw+UMTE+bvJr7Sz4OG+dGvu/V2PFJlZc7CIW3q34JFvdzD9+i6UmJ2kFVsYfoG3hqv67+v1G7oy9sdkRnVvxuOD2vLdliyeGNyWIL2WcquT5xfsYeyw9jQLD8TpVlh1oJCXft/LmnED0Gpkft2Vy+XtogkL1LEzq5xrP1jP7Re3YNp/upBbbuPS6d6a8V8f6UvXBP/7rtjs4LdduYy5NInDRRYUVaVdrLcgpf9rq8gstfLn2CtIjDRSanHS88XlDO4Yw2bu4mhjyiv5Ktx7XRVnE2R9TclxdXNvo6KwOjOHi04gyGht1TG/4DAAF2sfp3/EHJbUCpo2pWfhluCyRP99mVPHIck2ZH0pT9t2c6DZRlYYg7Bl305YYAWmou7MMbzE3S2hp8nArOJDbFY68L77WtYqXQHvM9SiGujs+LLetD2smc9Y3Q9c5niHFoHbSElczXvZNpbL7VhhiKSg8Ba/9Ud2bcrvyXm+z9qQFFRVxwc3DmZ4+24A2JweOj6/hPZSJgZcFKgRFOCtsWsVZWSledRxr9nRbmkWy54Gmrk3lofKyvnwOLVfKYn/hdUvA/BNaDDTI73ndTFf8vnomnyY2eHmku/8a49T0jJ9Gdu2Tic/5+SzNCiQp6sKSF8oLmGE2YpeVbkpPo48rZaRZgsTS8p8+yht2Y8maWvrTVuyQc/tzbx/k6Z900mffhVJ4xeyyfg/hrSIJ87tZm5uPpEexfuOv2clfD6wZgcPrAdTPnxzPVCTCa+d7pS0TDYEN+H+6OCa2tXn8mu6lAx9CZZNPOY1BOD+NfBJ/5rPAWFgr1twVN2s3/FsCbd/tokFxVf5vhvSvBldHE5eKC7lsloF39VBTnWanykpwy5JvFNPzVW1B8sqGGSxckNVLdLRgZIKbAwI4BK7Halq3/eWV/BYmX+abZKEs6olSr0e2QqHlsHSCTXLet0FW2f6HUsFLJJEsKr68mMVuliMrgLuiYvhgfIKXJ1epd/Q60BjgJJUiLsAXHaQJEhdAd/d5n/s+9eCMRryk2Hd25C5ETpdCxc/AC36wPREuOhu6H0v6I2w4GG48WsoS4NDy6FpV+//173lv98BE6HvY1CRDfsXgqyB5n3AWswOqQN3bBgJeO/JWXf19r6Xxi/05e+Y7L2GW9NLaWJNpZUrjaS5Nc2UdRHrCYj7rc6l9NgSCNB76N2iFetz1td/vRsggrlGJII5r+qM0KFpI3wZ2GpdZnUBvCVjOrylPE5JIl2nZYnRyFCLlZYuF32qMhRb0rPYo9dzocNbK2WSJHJ0Wlo5XawwBjGiqnTo73o7IoyZ4cduHrAoK4dYt7dvVfUxHRLoVHggLpqNgYGkpGX6AqXkyUMJrcpcPzp3B7/tykVGqXqwyTx3eTRv/JnDfzTrmD5mOBQfgoReFFgVYucO4wXXaOIGP4YsS7yy2FuKXx3MqarKLztyuLJLUwJ0GpKzyymxOBnQ3htg2l0eAnQaXwaymhY3etxYqWk2cjJ8DyvwCwhPVL+2Uaw9VEzfNpF0TQhnzqYMkl8Y6iv9Bfh+SyY9W0TQtirjmlpoYs6mTJ4f2Ykis4OYEAOlFievLTnAlFGd2Z9v8p3jtomDiQw+9QySqqpc+cYy7h/YjmtjS8HjhMRLAFh7qIh3Vhzi+/svQSM3xl0HZRYnaw4V0TQskN4tm/DszynM/SsTg1YmLiyAT//Xi7YxwaSVWGgdXX+fFY+iYra7CQtquBbkeJ6et4sft2WzfdIQVu4v5Ol5u5g5phdXtItBrjrX3HIbwxb0BsC072XSp19dZz/Vf/tf39WbO6pq+KDmvj1akclBdMjJ/14Ot4f2E5dwb7+WPHdVJzyKyhvLDnDPZS39fv8Ss4MjxRYuSjq5/iwT56fQLSEcnUbmie93Mqp7M965pcfxNzyOFXsLuKxtFAE6b2m8qqoUmhzEhp7c3+OhAhNfb/z/9u48Pqr63v/4+zPZ2NeENUBYZRPZiiKouKGi1arYaq1bXarVevXe3rrWWvRqta1Wra216s+ldavWitalbtXaugAuKCgKChJACCBryDrf3x/nzOSQzCQhJDlnzOv5eMyDmTNnznyT+ZIz7/PdVujnR49Jfj4btpUrOyum6Y9OrLN/2Zrj1K7vXyVJ5esPUF7+q6rYuK9e3P4XDaiqVqmZTFJ755JfGGNfnKT4wId2Os51q6r0Wvl0/aXiSC3PO01Szd+B33a8SpcN9LpV20c/VTxWLtvjxuRrt3/2I8XLay6aTY0t0pB+v9fczp00Qhfq8dPO9lp/VKrueZ+puGK4sl1M44t66+3lNeGz0Eq0wXXWjjR/w0xx5WuLSuR90S3QJpUqT9vVPuX+t393og4Z3Ut7XPmcJOniQ0bopL0HqFfnnY8/+doXNHVovn6w/xDvuJ3z9NyHX2pgjw666N5XdETW25rzk58o9+YRKd8nnQp5Y1zHt0D3q2BoSeX16b9R16EHSyVLJJk2fvRXHfC5d5HuV5Nfx/PtowAAIABJREFU0GFjdh4jP+JXFymv4CVJ3li0X5ds0Ja+41S6bpG6xONN6+528SKpfXfvy/bT/y3Nr2kZLfvRfH3j6eMkSe2Kb9a8Kw7Rq5+U6IAHh0mSjiu/Wn+99kfSNT2lbgOliz6Q1iyU/rCfdMaz0qB9/V/EY9LjZ2ppTo4KTvizug6cqn/cOkJjKyrUr6paunqzPl09T8Nclqz3GCm71t+k9Z9Kfz5B2u9/pLkXSLN+JY0/Wbqur9RvgnTy41LHntK6j6Uufb0gJ0lbVks3+eOKT3vaK8/aRVLXQqmD/zfpyQukdx+QjvqNNOl0acV/pHtnaV67PH3fb51LBLFqed89YvLGM+8duPDy7vgrtGWPmaqorlCX7I7qYFnS9f0lt3NLVnGH0SosXSzldpYqAq2Z+SOk9Z/U/1kd+wcvHL/4M+mE+6ThM2suaiaG3AyZIZ36ZM1rnJOeOFda+HBy05WVZ+jHV9yozjlOWR8/JY05zitnVgPj9O/YT9rnPKlgpPd5d0zdurjLSpZoeWmeyioqNbIw36uPaazdUqZDnvB6D91zwKvJc0vRpX9XO5XrmiMG6YQDJtV5Xe0eOTld5+ngcdJtR1yhnFiO5hd/ptm3L9Qpew/T1UeP0jVvXqNJvSfp8tcvr3Os2qb0maK7D7u7wf1aG2Euw/194Rp1aZ+t/YbX7b54w62D1Kequt4uEZJ0S+e+WlI+Tr+reL7Oc69U76UDs1J35dxdBwzsv9Oi6h98/oWW5WRreyyWHBybSpWkapPWVhdo/4pbJO38BbayOq6/L1yjix55L9masKWsUlP+70Xdc9o3tO+wWn+UNn2h6s6FisVMf3pzhX765KI6x2ysdVvLdPlfP9ipO50kZcdMVf7Vtph53dcO+vWrqQ6RtCthrm/Xdjpn/yH6+VOLk9s+/b8j9OLitZo2PD8ZdJvD2i1lWrelXHsWNtxfP+pWbdqhTnnZ6tq++X4/DSmvqtbKjTs0rJcXGDfvqEz5/omLMQ2FueW/OFJrNu/Q+X9+R7ecOEEDenSos29zlDknFkuGmZawrbxK5z6wQNcft2eL/AzNrayyWt94cLwkqXLrKOV09rpnlq48XR0G3CtJKl9/oPLyX1HZl0ep51ej1MVKdUhsgZ6KT9XJWS/p9uELJXlXnbsMnyOX7Y3hddW52vbJnOR73Z9zvVa7nrq06pzktkTL7daPfiHFytR5j6u9smwep7LVJ6r2ZNMDs5bry+5LtX/BSbrrtCl1vvDcOHucvj15QJ3tT/9oukorqrV+W7kmD+quo257XQ+evbfysrO0342v7LTvP388QzN+9U9J0vkHDtXtr3gtitd+a6yu/NuH+vuF0zWmX9ed6u6uuuPVZTpuYn8vAN51qFTsX8g47i499pf7NTvrtZqdRx8jLX5SOuw6afW7UsnH0pcf7DQOqDncdtBtmnH3MVqZna1O8bgO6nSsqnrOSz5/QqdRuur4R+u8bth110mK67dHn5VsqU74zgN3anH8Nv16/5s0c/tW6bEzpHNe9b5Y3zpBKtsknfWS92V77SKvZWXZK9IjJ3tf/gfvL904uOaAV9dquXLOa2EZ8y2phxeaE39zJlbfrfu+P0XOOdnPvaB+cuHz+vNZ+0gbP5c695FyUgd2SdJbd0q9x0hF0/z39n/X7bpJl65oxG80he0bvBCa07SLo5K8oSqPfM/7Pfbz/u+qYrvW31CoAwcWql0sV/OWLfW2X75GevlaadQ3kxcZ/7ni39peHteRI/ZLffzqKum5S7wJ7N77s3TlOu89R39L2rzS+71tX+8Fo9XveUFz2cvSnrO9n23HV9INRd6xfrohfeDasEyKZXvHqx2GJenNO6TnLtGO7/9TFfljd+viY9gSdfLeGa9q0qCaMCdJH/78MHXKq/s7qv037LPrZtU5d324arNG9O6s3Oyd/07+afGf9Frxa/p448c6Y+wZumnBTbpu+nUq6FCgs/9xtqb1m6Y7Dm38sIbWQpj7OgtMmHJ15am6t/pwSdJY+0y/zLlTV1WernluZHKfHFWpv5VoueurTvJa4baqg9qrTBdk/023VB2vfrZe34gt0YL4CFUoR6/n/dcuFen+qkN1anbN4uqH9R6tDe226NovOmhjZX8Ni63WXVWzNDvrNc3MWqAHqw7SrVmn6pJZo/WTJz5Wlqo1vGeuSjeu1ueub3LMVu0vBVXVcQ274lld+62x+p7fza0xEl18Hj9vX00a1PSB1PG4S3bH7N0lTw+dvU8yvN3xvYk6fGzf5B+cSw4fqRue+7jOMT7NO0U5Vq29y36rteqh3508URMGdtPU61/eeb9Aq2zimFOKeujRc6c2ufwI39BrblZOt3kqW3Vyyi+9J9/1pg4d1VunTxuc4tVoDYkvGhUb91Vuj/9I8sJVu/5/UsWGAxQv76W8gpdUXnKo5Hb+QvWDA4bowXXfTr6m49BfKpa7QTuKv6fqHQPkqtKHjSuPHKWbFv1QWe1XeWFOTu36P6TKjfuoeseQOvvfc/pk3f365/r30g2aObq37jx1cs3fisE9tGLDdr11+SGSpPvfWK4h+Z00fXjDV+LXbSnTlOu81qMzpw/WT48anTzua/97oPb/pRf2Pr9+1k6too8tKNbaLWU6/8BhDb5Hg3Z8JS24V5p2kYoue0YF+krz2p3vtehMOXvnfV+/WXrxaunHn6routeU2/Nfyst/OdVRG3TBuHP124Xel7r3T31fMYvpob+/oE1v3Kcbqk5Ul37PqzLL60K98NyHlZNV9wt14neVOCfUtnzzchV1LfIelG+V8rweFNpWIm1c5nVvq8/VXaWRR0kn1u2mn0qiPl84+Emd7beK6u0/atsX7yvr6FvUPjfV3L2N8MFj0vJ/SQdeIXVKPWSi1VSU1um2v2bbGs18fKYKOxXq2fE/8X7PhU3+XizF41K8MnXQasi2Eq8lMdbE37XkBfWK7VJe+LOi7q6Rv/22qreN1MMnXZz8TtbQxaBlJdvknNMhN71W7367ojperV/N/5XOGHuGenUIuQ6nsLthrrkWDUcL+PjU9/SXu3+ph6sPSnZ7OW3qIO0/YrKOuG/nE37/bu21atMOHTxtX10+a5Q+WrNFc99frfXbyvXrE/bScx/uqwXD87WptFJ9u7bTUwtX6+JH3tc+Zbfphl4v6LR139GI3p31jwunaemaDRrUs72yqsoUW/S416e6fIuU00FXXfEPTYl9rJGxlfp79RQtWXGRJOncWmW/7vLLtMe1z6hcOXryB9PVo2OuKrVUlcrWVnXQctdfj583Vcf//o2UP3t2VqxJ/4Hb52Y1y3/84FWgvOwsDfG77fXr2i550r7mW2O1bN02nTdjqB6e94VWbCjV2fsNVn6nPB08qpdG3HSfclWlcuWqfU5Wcqzb65ccqOk31FwRjwcuqLz6vzP0gwcW6N7vf2O3fwaEq6jDBC1blb4b2Z/PauCLHFrRzld9y1Z9L3m/fN2s5P3EOCRJOm1qkR4M9JDaUXyycrouUNXW0ardqvbDGUP1u38uSz4+a78huvbvP5SSM7qaylbVtOQ/ft6+Ov73Xri8+Tt76aCRvVVRFde/l25Q7clyH/3Bzhd9Tp1a1JgfWJLUK9Bl9adHjZYkPXPhflpYvEkDe3bQG5cdpFVf7ZCZ7dS9dfakZpycq313afrFyYcl6l63FSph2kXSlHOk3I5aMudYbdx+mGb+bV8dP/x4XTjxQh3wyAF1XjJjwAz1at9Lj35S07L23invKSuWpUVfLdErK19RzLzP66QjD1XFYQfrvOyYpKOSn3WqINcYySAn1QQ5SepU4N0acvmaXQoU3xn6Az32wTydtm/gfaecrU5TGn2I1Pac7d2iILduq3+fjn105tgzdezwY6Uujb/4m1YsJsWaOAShMZ9rQ8y+FkFOksqKvS7m4wfUjFmcc8wY/eHVz9K+JjFMom/XdlrTwCRWjZUVy9IlUxqesC1TEeYizLXvqburvWBy3oyhOm5CfxXld1ROVkyfXHuERlzpzfLz3b0H6rwDhirunPp3a6+smGls/64a27/myvARfpBITPpw7IRC3fjcElVU9dUB//2A3t1e4Y1NycrSsMLEzFBdvD7XUrJfe/ucLF1eeab+mne1bqg6KW3Z8zvlackvjk0+rqqOa0pRD1186Ahd+leva1KPjnlqlxNTWWX4My7V55LDvdbP5y7aT/271XRNOSXQYtiva3ut2FCq4ycVamQfb/IEp5jK/VXH3rri4OS+hd13PhkFG8cH9eyo5y7aX8h8l88apTPvo/fB11XtUBUv76fydXWn95ekc/Yfoj+9uUJbyoIzzGZJrubqfU6WqbLa+2MQ7FVw7AQvONXuRPOD/YfoD6+l/0LUWJ9dN0vVgYOP7tdFo/t5f8P6dm2vvl3r6Y7X2sy87mzyLrL17dpZr5/4ujrldFJWLEvvnPKOjn7iaI3vNV7n7nWuPlj/gY4a4k3AML7XeP3mnd9on777KMtvNbn1oFvrvEXtblvZjeiaXHu8e7NJEVzqc+X0C3Tl9JYpSpSZmS6adFHYxUA9gmPnT51a1KiLTi//zwxVRWBGzkxAmIuwxPl1ZJ/OyUCRkDjhZMdM1x27Z5OO/59La2ay6t6xcbMpfnD1TJkdJsUu1t1rt+rQm1/TD2cM1Z79u2pyUQ/9bO6H+nhN3TF+2VmxlN0G37rsEJWnWAg6Svp09a7QJUJaKreeNEFPvb9ae/Suufr6v4ftoV8+v0SSmnXMGzJDe3/ijmnD0q8PhGip3DKm0fuaTKVfnKl4ZcPrf3XrkKuFVx+201iQxCyzQws66qdHjdaMPXrVGStyeGBSjXH+le1vT/Ymcrhs1ihdNmuUdlcsZoo1y9RY4eiaV3PRMieWo2ePr5nKfFCgleabQ7+pbw6tO3a1Pm9ffnCdcBf00v8coEfmrUxOpgWg+Xjdgneju2obQpiLsMTMdbVnyUq469TJyem3m8KasLh1duAK5PDenfWvnxyofn5roCT97uS6MxPV9odTJume1z/XoB4d/O6M0Qw6NU38Df+eCjrn6fvTdx77lJggoz63nTQhOVsfvl6mDO6hU6cO0rmBJUcQLVXbByu74+eS/IlI0hhX2FULi72uf9cft6cWr94iM6l6+3BJ0sfXHK6fPLZQc/1lKoIeOjt1d9ox/broP8s26G/nT0v2mLj9uxP13kpvKvra3cX7d2vfLF3I0Xi9Gpg5dWhBJ13eDIEaAHYHYS7CCjrn6b2rDk3bqnPI6N4pt7empsxaN7JPF904e68WKE3zuveMKfrl80u0Z//mn/Vxv+H5+s43Buiocam7ZSHzZWfFNOeYsWEXA/Wo2jbaC3Mp5gF77Nypmn2HN6b36qPHaOJAr+vjSVO86evXbvHGchR0zlO7nCzdetKEZJgb3quTPl23TZI0dWhNy+zls0Ymu1nfccokfbR6SzLISdKR4/rqyHG7t9hxJnvuov30ZTONkQGAtoIwF3HdOjSu+yOa3x59Ou+0EOyual9Pi9sDZ+7d5OMCaFmNaQHr6E+pfdiYxl9UO2f/mlbaLu1ytPcQuuAGjezTpd7u7ACAughzQAsZ56/jduPx40IuCYDdkWoFn0552Zp3xSHqnsFrQAFAS1pw5SGqjoezBFpbQpgDWki3DrmMcQEyTIfAWlwTBnbTu19sSrtvYlxzbd3pUQEA6tmpiUs8YJe00Hy6AABkiMAcR69fclCKHXbtyvLtJ0/cvfIAANBItMwBANoml0hxXlgb0KO9egSWadnV+X7fvuJgdWmXwwy1AIBWQ5gDAKAeqcbMpdKr885T2de3RhkAAM2BMAcAaJPiFd5MlNVl/SXVDW3jCrvpnS82qXvHXR8D9/olB6pDLqdYAEDL4kwDAGiTqrcP17Zl/yNXkZ/y+ctnjdLxEws1tKDTLh87sZ4cAAAtiTAHAGizXEVBzf1aLXO52THt6S8xAgBAFNGhHwDQpv386DFhFwEAgCYhzAEA2rSDRvYKuwgAADQJ3SwBAG1a/27tddKUgTpln0FhFwUAgF1CmAMAtGmxmOn64/YMuxgAAOwyulkCANqkw8f0UU7Wri4NDgBAdNAyBwBok+44ZVLYRQAAYLfQMgcAAAAAGYgwBwAAAAAZyFztVVJb643NSiStCOXN65cvaX3YhUCbRN1DGKh3CAt1D2Gg3iEs6ereIOdcQVMPGlqYiyozm++cmxx2OdD2UPcQBuodwkLdQxiodwhLS9U9ulkCAAAAQAYizAEAAABABiLM1XVn2AVAm0XdQxiodwgLdQ9hoN4hLC1S9xgzBwAAAAAZiJY5AAAAAMhAhDkAAAAAyECEOQAAAADIQIQ5AAAAAMhAhDkAAAAAyECEOQAAAADIQIQ5AAAAAMhAhDkAAAAAyECEOQAAAADIQIQ5AAAAAMhA2Q3tYGb3SDpK0jrn3NgUz5ukWyTNklQq6XTn3DsNHTc/P98VFRXtcoEBAAAA4OtgwYIF651zBU19fYNhTtK9kn4r6f40zx8habh/21vS7/1/61VUVKT58+c3rpQAAAAA8DVjZit25/UNdrN0zr0maWM9uxwj6X7neVNSNzPruzuFAgAgTJtKK8IuAgI2lVbIORd2MQAgcppjzFx/SSsDj4v9bQAAZJwPV23W+Dkv6G/vrgq7KJC0dN1WjZ/zgh56e2XDOwNAG9McYc5SbEt5+czMzjGz+WY2v6SkpBneGgCA5rV4zRZJ0mufcp6KgqXrtkuSXv54XcglAYDoaY4wVyxpQOBxoaTVqXZ0zt3pnJvsnJtcUNDkcX4AALQYS/6b6lolWpvZzv8CAGo0R5ibK+lU8+wjabNzbk0zHBcAAAAAkEZjliZ4SNIMSflmVizpZ5JyJMk5d4ekZ+QtS7BU3tIEZ7RUYQEAaC0u9YgBhIT5TwCgrgbDnHPupAaed5LOb7YSAQAAAAAa1BzdLAEA+NphzFy0MGYOAOoizAEAAABABiLMAQCQAmPmooUxcwBQF2EOAAAAADIQYQ4AgBQYMxctjJkDgLoIcwAApEA3y2ihmyUA1EWYAwAgIJEZaJmLhkSIo2UOAOoizAEAAABABiLMAQCQAi1B0cLHAQB1EeYAAAAAIAMR5gAACGKijYjhAwGAdAhzAACkQLe+aKHbKwDURZgDAACRxZIEAJAeYQ4AgADWl4sWlooAgPQIcwAAILLiftMcIRsA6iLMAQCQAmO0oiGeWDScljkAqIMwBwBACozVigZHyxwApEWYAwAgBaJDNCRCNeEaAOoizAEAEEBoiBZa5AAgPcIcAAABcVqCIiUe9/7l4wCAughzAAAE0BIULXwaAJAeYQ4AgIBkyxwxIhLiNJECQFqEOQAAgggP0UK3VwBIizAHAEAAmSFaaCEFgPQIcwAABMRr+lkiAuLJz4EPBABqI8wBABBAZIgWulcCQHqEOQAAAmiYi5bEBCiEOgCoq1FhzswON7MlZrbUzC5N8fzpZlZiZu/5t7Oav6gAALQ8lwwPpIco4FMAgPSyG9rBzLIk3S7pUEnFkuaZ2Vzn3OJauz7inLugBcoIAADaKkI1AKTVmJa5KZKWOuc+c85VSHpY0jEtWywAAMKR7NYXcjngodsrAKTXmDDXX9LKwONif1ttx5vZQjN7zMwGNEvpAABoZTQERQvdXQEgvcaEOUuxrfZf1qckFTnnxkl6UdJ9KQ9kdo6ZzTez+SUlJbtWUgAAWkGc7BApyZY5Qh0A1NGYMFcsKdjSVihpdXAH59wG51y5//CPkialOpBz7k7n3GTn3OSCgoKmlBcAgBaVWKSa7BANrta/AIAajQlz8yQNN7PBZpYr6URJc4M7mFnfwMOjJX3UfEUEAKD1EOKihRY5AEivwdksnXNVZnaBpOclZUm6xzm3yMzmSJrvnJsr6UIzO1pSlaSNkk5vwTIDANBiHBOgRIpzO/8LAKjRYJiTJOfcM5KeqbXtqsD9yyRd1rxFAwCg9REaosURqwEgrUYtGg4AQFvBhBvRwoQ0AJAeYQ4AgABagqKFTA0A6RHmAAAIYJHqaGERdwBIjzAHAEBQIjzQJBQpfB4AUBdhDgCAgOS6ZmSHSCDEAUB6hDkAAAIS3frihIhIYAIUAEiPMAcAQEAiwxEiooFMDQDpEeYAAAhgaYJooYUUANIjzAEAEJBYmoCWuWhgDCMApEeYAwAgKNnNkvQQCYxhBIC0CHMAAATUTIASckEgqeZzIMwBQF2EOQAAAhxj5iKFbq8AkB5hDgCAgJoJUMItBzxMSAMA6RHmAAAIqGkJIjxEAUtFAEB6hDkAAAIcY7QihXANAOkR5gAACHBMgBIpjm6vAJAWYQ4AgICadc1ID1GQ+Bz4PACgLsIcAAABLE0QLXHGzAFAWoQ5AAACGDMXLXweAJAeYQ4AgABagqKFllIASI8wBwBAQHU8LokxWlFRHWfMHACkQ5gDACCg2styzJ4YEdWOpQkAIB3CHAAAAYmWOcJDNFRXJ1rmQi4IAEQQYQ4AgIBqxsxFCi1zAJAeYQ4AgIA4Y7QipebzCLkgABBBhDkAAAKq6GYZKVVxWuYAIB3CHAAAAYkJUOhmGQ3VLE0AAGkR5gAACIgzRitS4rTMAUBajQpzZna4mS0xs6VmdmmK5/PM7BH/+bfMrKi5CwoAQGuoYoxWpPB5AEB6DYY5M8uSdLukIySNlnSSmY2utduZkr5yzg2TdLOkG5q7oAAAtIayimpJtARFRVklnwcApJPdiH2mSFrqnPtMkszsYUnHSFoc2OcYSVf79x+T9FszM5dhU4E9+8EaLV6zJexiAABCtHzDdknS+q3l+vU/loRcGixbt02S9FVpBZ8HgCbr07WdTt57UNjFaHaNCXP9Ja0MPC6WtHe6fZxzVWa2WVJPSeuDO5nZOZLOkaSBAwc2scgt58WP1umJd4vDLgYAIGRDCjpq5cZS3f7K0rCLAklD8juq+KsdfB4Ammz8gG5tNsxZim21W9was4+cc3dKulOSJk+eHLlWu19/ey/9+tt7hV0MAAAAAGhQYyZAKZY0IPC4UNLqdPuYWbakrpI2NkcBAQAAAAB1NSbMzZM03MwGm1mupBMlza21z1xJp/n3Z0t6OdPGywEAAABAJrHGZC4zmyXpN5KyJN3jnPs/M5sjab5zbq6ZtZP0gKQJ8lrkTkxMmFLPMUskrdjdH6AF5KvWWD+glVD3EAbqHcJC3UMYqHcIS7q6N8g5V9DUgzYqzLUlZjbfOTc57HKg7aHuIQzUO4SFuocwUO8Qlpaqe41aNBwAAAAAEC2EOQAAAADIQIS5uu4MuwBos6h7CAP1DmGh7iEM1DuEpUXqHmPmAAAAACAD0TIHAAAAABmIMAcAAAAAGYgwBwAAAAAZiDAHAAAAABmIMAcAAAAAGYgwBwAAAAAZiDAHAAAAABmIMAcAAAAAGYgwBwAAAAAZiDAHAAAAABkoO6w3zs/Pd0VFRWG9PQAAAACEasGCBeudcwVNfX1oYa6oqEjz588P6+0BAAAAIFRmtmJ3Xk83SwAAavliQ6mcc2EXAwCAehHmAAAImL98o/b/5St6eN7KsIsCAEC9CHMAAAQsXbdNkvTeF5tCLgkAAPUjzAEAEJDoXGkWajEAAGgQYQ4AgACGygEAMgVhDgCAgLif5oymOQBAxBHmAAAIoJslACBTEOYAAAhKtMyFXAwAABpCmAMAIICWOQBApiDMAQAQkJgAJUaaAwBEHGEOAICAON0sAQAZgjAHAAAAABmIMAcAQAosTQAAiDrCHAAAKThWDwcARBxhDgCAANrjAACZgjAHAEBAonsl7XIAgKgjzAEAEJAYKkcvSwBA1BHmAAAAACADEeYAAEjB0dESABBxhDkAAAKYAAUAkCkIcwAApMCYOQBA1BHmAAAIYrFwAECGIMwBAAAAQAYizAEAkAK9LAEAUUeYAwAgBcbMAQCijjAHAEBQMsWR5gAA0daoMGdmh5vZEjNbamaXpnj+dDMrMbP3/NtZzV9UAABaHhEOAJApshvawcyyJN0u6VBJxZLmmdlc59ziWrs+4py7oAXKCABAq4nHiXMAgMzQmJa5KZKWOuc+c85VSHpY0jEtWywAAMKRyHKMmQMARF1jwlx/SSsDj4v9bbUdb2YLzewxMxvQLKUDAKCVkeEAAJmiMWEu1eqptc91T0kqcs6Nk/SipPtSHsjsHDObb2bzS0pKdq2kAAC0Auc3ydEyBwCIusaEuWJJwZa2Qkmrgzs45zY458r9h3+UNCnVgZxzdzrnJjvnJhcUFDSlvAAAtChCHAAgUzQmzM2TNNzMBptZrqQTJc0N7mBmfQMPj5b0UfMVEQCA1hNPtMzR4RIAEHENzmbpnKsyswskPS8pS9I9zrlFZjZH0nzn3FxJF5rZ0ZKqJG2UdHoLlhkAgBbDBCgAgEzRYJiTJOfcM5KeqbXtqsD9yyRd1rxFAwCg9dEiBwDIFI1aNBwAgLYi0SJHpAMARB1hDgCAAEf/yshZubFUldXxsIsBAJFDmAMAICAxZi7VujxofVvLKrXfja/oiic+CLsoABA5hDkAAALitMxFSlml1yL30kfrQi4JAEQPYQ4AgACyXLRkx7w2UrpZAkBdhDkAAAJccp05REFy3T8+EACogzAHAEBAYswc3S2joZpwDQBpEeYAAAhIrjNHeoiE977YJEnaVl4VckkAIHoIcwAABNAyFy2L12wJuwgAEFmEOQAAAlg0PFoqqpj4BADSIcwBABCQmAAlTpqLhI552WEXAQAiizAHAEBAzeyJpLkomDyouySpoHNeyCUBgOghzAEAEPDHf30uianwo6LabyLNzeIrCwDUxl9GAABScIyai4QqP8xVxRk7BwC1EeYAAAg4dkJ/SRLZIRoSLXNrt5SHXBIAiB7CHAAAAYnufLTMRUMVM9EAQFqEOQAAAjbvqJTEbJZRUe03kfbsmBtI525pAAALH0lEQVRySQAgeghzAAAEPLfoS0lMgBIVxV/tkCRV84EAQB2EOQAAUmBpgmh48O0vJEmbSitDLgkARA9hDgCAFIhy0XD6vkWSpD5d2oVbEACIIMIcAAABvfzFqeO0zEXCnKcWS5K2lNEyBwC1EeYAAAgY06+LJMbMRUViNsvSiuqQSwIA0UOYAwAgoNoPcbTMRUtiyQgAQA3+MgIAEBBnTYJIOXXqIElSv26MmQOA2ghzAAAEVPnrmlUT6iKhfU6WJBYPB4BUCHMAAAT4WU4VVfFwCwJJ0kdfbpUkVVUT5gCgNsIcAAABicWpK6sJc1Hw2iclkmiZA4BUCHMAAAQkuleW0zIXKdVxPg8AqI0wBwBAQKJFjpa5aKGbJQDURZgDACBg8w5vcepKwkOk0M0SAOoizAEAELCp1AtzTIASDbnZ3leVKrpZAkAdhDkAAHzlVdXaVl4liW6WUZEI1bTMAUBdhDkAAHyJVrm87JgqCHOR4hwLugNAbYQ5AAB8G7dXSJJ6d2lHN8sIqPIDdaKrZSVdLVFLaUWVPlm7NexiAKFpVJgzs8PNbImZLTWzS1M8n2dmj/jPv2VmRc1dUAAAmtu+17+kix95Tys2bJcknXnvPElS7y55dLOMgE3+ZDQFnfIk1SwbASR887bXNfPm17SptCLsogChyG5oBzPLknS7pEMlFUuaZ2ZznXOLA7udKekr59wwMztR0g2SvtMSBQYAoDn8Z+l6rd5cpifeXaUn3l2103O9OrdT3HnhYUdltTrlNXi61KbSCt3z7+W69aVP6zx35ymTNHNMn3pf/+nardpSVqkRvTurc7ucXfthmpFzTstKtmtYr06t/t4VVXGt/KpUg3p00DVPL9Z9b6yQJG1JzDBa5aTcVi8WIipRVyVp/JwXtPwXR4ZcopZxyE2v6sGz9lavLu3CLgoiyJyr/yqXmU2VdLVz7jD/8WWS5Jy7PrDP8/4+b5hZtqQvJRW4eg4+efJkN3/+/Gb4EZrPl5vLdP6D7yg7ZvrhgcN0wIgCSdK6rWV6/dP1emPZBg0u6KiDR/bWms07VNA5T397d5Uqq51e/aREJ0wuVMxM8z7fqE/WbdWxEwq1dnOZ8nJiGtuvq/7ff5brozVbQv4pgcYZ06+LFq1u/vrauV22tpZVNftxM8kho3rpxY/WhV2MNmNE7076ZO22XXrNxIHd9M4Xm1qoRNhV/3XwcN2SIiS3VcN7ddKn63atTqNtG1LQUZ/5wbet2quwq568YHrYxajDzBY45yY3+fWNCHOzJR3unDvLf3yKpL2dcxcE9vnQ36fYf7zM32d9rWOdI+kcSRo4cOCkFStWNLXcLWLCnH/oK3/wuyTl+9061m8rD6tIAAC0efd9f4pOu+ftsIsBIMNFsfV2d8Ncw/1GJEuxrXYCbMw+cs7dKelOyWuZa8R7t6qHztlH37vrLXXIzVa/bu3ULidLuVkxjenXVas37VBudkwPvBmtAAoAaD5nTh+sH8/cQxtLKzTtFy83+TifXHuEPlm7NdlF84hb/lXv/t+eXKh/LinRj2fuoalDe+o7f3hDqzeXNeq9TphUqL8sKE77/JF79tVbn2/cpQuTt393os5/8J2dts2eVKjH6nmfnCyrs9B6bnasyRPJ3Pf9KckeMq1l2rCe2lZerbzsmN7+fGOrvndzaYu9H/p3a69Vm3aEXQwgFHSzBAC0Sc99+KXO/dMCXX/cnsrLjmn68Hz16hzdMSkrN5aqS7scde0Q3ng6AEDzao2WuXmShpvZYEmrJJ0o6bu19pkr6TRJb0iaLenl+oIcAABhO3xsn0h2uUlnQI8OYRcBABAxDYY551yVmV0g6XlJWZLucc4tMrM5kuY75+ZKulvSA2a2VNJGeYEPAAAAANBCGtMyJ+fcM5KeqbXtqsD9MkknNG/RAAAAAADpNDhmrsXe2KxEUhRnE8mXtL7BvYDmR91DGKh3CAt1D2Gg3iEs6ereIOdck2d7Ci3MRZWZzd+dQYhAU1H3EAbqHcJC3UMYqHcIS0vVvVhzHxAAAAAA0PIIcwAAAACQgQhzdd0ZdgHQZlH3EAbqHcJC3UMYqHcIS4vUPcbMAQAAAEAGomUOAAAAADIQYS7AzA43syVmttTMLg27PMg8ZnaPma0zsw8D23qY2Qtm9qn/b3d/u5nZrX59W2hmEwOvOc3f/1MzOy2wfZKZfeC/5lYzs9b9CRFFZjbAzF4xs4/MbJGZ/Ze/nbqHFmVm7czsbTN73697P/e3Dzazt/x69IiZ5frb8/zHS/3niwLHuszfvsTMDgts59yMlMwsy8zeNbOn/cfUO7Q4M1vunw/fM7P5/rbwzrfOOW5eV9MsScskDZGUK+l9SaPDLhe3zLpJ2l/SREkfBrbdKOlS//6lkm7w78+S9Kwkk7SPpLf87T0kfeb/292/391/7m1JU/3XPCvpiLB/Zm7h3yT1lTTRv99Z0ieSRlP3uLX0za8Pnfz7OZLe8uvUo5JO9LffIek8//4PJd3h3z9R0iP+/dH+eTdP0mD/fJzFuZlbfTdJ/y3pQUlP+4+pd9xa/CZpuaT8WttCO9/SMldjiqSlzrnPnHMVkh6WdEzIZUKGcc69Jmljrc3HSLrPv3+fpG8Ftt/vPG9K6mZmfSUdJukF59xG59xXkl6QdLj/XBfn3BvO+99+f+BYaMOcc2ucc+/497dK+khSf1H30ML8OrTNf5jj35ykgyQ95m+vXfcSdfIxSQf7V52PkfSwc67cOfe5pKXyzsucm5GSmRVKOlLSXf5jE/UO4QntfEuYq9Ff0srA42J/G7C7ejvn1kjel25Jvfzt6epcfduLU2wHkvzuQxPktZBQ99Di/K5u70laJ+8LyTJJm5xzVf4uwfqSrGP+85sl9dSu10ngN5J+IinuP+4p6h1ah5P0DzNbYGbn+NtCO99mN/GH+DpK1R+VqT7RktLVuV3dDkiSzKyTpMclXeSc21JPN3vqHpqNc65a0ngz6ybpCUmjUu3m/7urdSzVRWfqXhtnZkdJWuecW2BmMxKbU+xKvUNLmOacW21mvSS9YGYf17Nvi59vaZmrUSxpQOBxoaTVIZUFXy9r/WZz+f+u87enq3P1bS9MsR2QmeXIC3J/ds791d9M3UOrcc5tkvRPeeNCuplZ4oJxsL4k65j/fFd5XdN3tU6ibZsm6WgzWy6vC+RB8lrqqHdocc651f6/6+RdwJqiEM+3hLka8yQN92dCypU3QHZuyGXC18NcSYlZik6T9GRg+6n+TEf7SNrsN80/L2mmmXX3Z0OaKel5/7mtZraP39f/1MCx0Ib59eFuSR85524KPEXdQ4syswK/RU5m1l7SIfLGbL4iaba/W+26l6iTsyW97I8LmSvpRH/WwcGShsubBIBzM+pwzl3mnCt0zhXJqxMvO+dOFvUOLczMOppZ58R9eefJDxXi+ZZulj7nXJWZXSDvl5sl6R7n3KKQi4UMY2YPSZohKd/MiiX9TNIvJD1qZmdK+kLSCf7uz8ib5WippFJJZ0iSc26jmV0j72QiSXOcc4lJVc6TdK+k9vJmOHq2hX8kZIZpkk6R9IE/dkmSLhd1Dy2vr6T7zCxL3gXiR51zT5vZYkkPm9m1kt6Vd7FB/r8PmNlSeS0jJ0qSc26RmT0qabGkKknn+903xbkZu+ASUe/QsnpLesIfxpAt6UHn3HNmNk8hnW/NnwITAAAAAJBB6GYJAAAAABmIMAcAAAAAGYgwBwAAAAAZiDAHAAAAABmIMAcAAAAAGYgwBwAAAAAZiDAHAAAAABmIMAcAAAAAGej/A6hFftk8UXX1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    pdict['w_len'] = 20*60\n",
    "    gen_tst = gen(cat_tst, pdict)\n",
    "    XX, YY = next(gen_tst)\n",
    "    ZZ = model.predict(XX)\n",
    "    \n",
    "    idx = np.random.randint(pdict['bs'])\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(15,5), sharex=True)\n",
    "    _ = ax[0].plot(XX[idx])\n",
    "    _ = ax[1].plot(YY[idx])\n",
    "    _ = ax[2].plot(ZZ[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "progressive training with increasingly noisy arrivals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building new model:\n",
      " models/f:45|k:15|d:1x2x4x8x16|s:2|bs:20|c_len:2|w_snr:10|c_buf:10|c_shp:gauss|c_amp:1|f_low:1|f_hig:10|r_smp:40|cmpts:ZNE|lr:3.3333333333333335e-05|pat:3|time:20-06-25-21-58-25|w_len:180\n",
      "Receptive Field Length: 10.85 seconds\n",
      "Model: \"encoder_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, None, 45)     2070        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, None, 45)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, None, 45)     0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 45)     30420       spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, 45)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, None, 45)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 45)     180         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, None, 45)     0           conv1d_2[0][0]                   \n",
      "                                                                 spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, None, 45)     30420       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, 45)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, None, 45)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, None, 45)     30420       spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, 45)     0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, None, 45)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, None, 45)     2070        add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, 45)     0           conv1d_5[0][0]                   \n",
      "                                                                 spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, None, 45)     30420       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, 45)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, None, 45)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, None, 45)     30420       spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, 45)     0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_5 (SpatialDro (None, None, 45)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, None, 45)     2070        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, 45)     0           conv1d_8[0][0]                   \n",
      "                                                                 spatial_dropout1d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, None, 45)     30420       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, 45)     0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, None, 45)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, 45)     0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_7 (SpatialDro (None, None, 45)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, None, 45)     2070        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, None, 45)     0           conv1d_11[0][0]                  \n",
      "                                                                 spatial_dropout1d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, None, 45)     30420       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, 45)     0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_8 (SpatialDro (None, None, 45)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, 45)     0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_9 (SpatialDro (None, None, 45)     0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, None, 45)     2070        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, None, 45)     0           conv1d_14[0][0]                  \n",
      "                                                                 spatial_dropout1d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, None, 45)     30420       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, 45)     0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_10 (SpatialDr (None, None, 45)     0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, 45)     0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_11 (SpatialDr (None, None, 45)     0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, None, 45)     2070        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, None, 45)     0           conv1d_17[0][0]                  \n",
      "                                                                 spatial_dropout1d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, None, 45)     30420       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, 45)     0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_12 (SpatialDr (None, None, 45)     0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, 45)     0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_13 (SpatialDr (None, None, 45)     0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, None, 45)     2070        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, None, 45)     0           conv1d_20[0][0]                  \n",
      "                                                                 spatial_dropout1d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, None, 45)     30420       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, 45)     0           conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_14 (SpatialDr (None, None, 45)     0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, 45)     0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_15 (SpatialDr (None, None, 45)     0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, None, 45)     2070        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, None, 45)     0           conv1d_23[0][0]                  \n",
      "                                                                 spatial_dropout1d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, None, 45)     30420       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, 45)     0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_16 (SpatialDr (None, None, 45)     0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, 45)     0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_17 (SpatialDr (None, None, 45)     0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, None, 45)     2070        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, None, 45)     0           conv1d_26[0][0]                  \n",
      "                                                                 spatial_dropout1d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, None, 45)     30420       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, 45)     0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_18 (SpatialDr (None, None, 45)     0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, None, 45)     0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_19 (SpatialDr (None, None, 45)     0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, None, 45)     0           spatial_dropout1d_1[0][0]        \n",
      "                                                                 spatial_dropout1d_3[0][0]        \n",
      "                                                                 spatial_dropout1d_5[0][0]        \n",
      "                                                                 spatial_dropout1d_7[0][0]        \n",
      "                                                                 spatial_dropout1d_9[0][0]        \n",
      "                                                                 spatial_dropout1d_11[0][0]       \n",
      "                                                                 spatial_dropout1d_13[0][0]       \n",
      "                                                                 spatial_dropout1d_15[0][0]       \n",
      "                                                                 spatial_dropout1d_17[0][0]       \n",
      "                                                                 spatial_dropout1d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, None, 1)      46          add_10[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 596,836\n",
      "Trainable params: 596,836\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0443WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 0.0440 - val_loss: 0.0128\n",
      "Epoch 2/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0115WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0115 - val_loss: 0.0092\n",
      "Epoch 3/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0094WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0094 - val_loss: 0.0078\n",
      "Epoch 4/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0082WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0082 - val_loss: 0.0067\n",
      "Epoch 5/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0070WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0070 - val_loss: 0.0058\n",
      "Epoch 6/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0063WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 7/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0057WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 8/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0053WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 9/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0051WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 10/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0047WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 11/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0044WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 12/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0045WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 13/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0042WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 14/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0042WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 15/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0039WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 16/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0040WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 17/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0039WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 18/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0040WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 19/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0037WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 20/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0038WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 21/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0036WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 22/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0036WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 23/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0036WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 24/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0036WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 25/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0035WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 26/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0035WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 27/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0035WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 28/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0033WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 29/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0033WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 30/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0032WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 31/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0032WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 32/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0032WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 33/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0032WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 34/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 35/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 36/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 37/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 38/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 39/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0027WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 40/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0027WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 41/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0026WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 42/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0026WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 43/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0027WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 44/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0026WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 45/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0025WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 46/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0025WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 47/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0026WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 48/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0025WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0025WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 245ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 50/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0024WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "loading previous model:\n",
      " models/f:45|k:15|d:1x2x4x8x16|s:2|bs:20|c_len:2|w_snr:10|c_buf:10|c_shp:gauss|c_amp:1|f_low:1|f_hig:10|r_smp:40|cmpts:ZNE|lr:3.3333333333333335e-05|pat:3|time:20-06-25-21-58-25|w_len:180.h5\n",
      "Receptive Field Length: 10.85 seconds\n",
      "building new model:\n",
      " models/f:45|k:15|d:1x2x4x8x16|s:2|bs:20|c_len:2|w_snr:8|c_buf:10|c_shp:gauss|c_amp:1|f_low:1|f_hig:10|r_smp:40|cmpts:ZNE|lr:1.1111111111111112e-05|pat:6|time:20-06-25-22-19-32|w_len:180\n",
      "Receptive Field Length: 10.85 seconds\n",
      "Model: \"encoder_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, None, 45)     2070        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, 45)     0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_20 (SpatialDr (None, None, 45)     0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, 45)     0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_21 (SpatialDr (None, None, 45)     0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, None, 45)     180         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, None, 45)     0           conv1d_32[0][0]                  \n",
      "                                                                 spatial_dropout1d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, None, 45)     30420       add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, 45)     0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_22 (SpatialDr (None, None, 45)     0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, 45)     0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_23 (SpatialDr (None, None, 45)     0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, None, 45)     2070        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, None, 45)     0           conv1d_35[0][0]                  \n",
      "                                                                 spatial_dropout1d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, None, 45)     30420       add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, 45)     0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_24 (SpatialDr (None, None, 45)     0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, 45)     0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_25 (SpatialDr (None, None, 45)     0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, None, 45)     2070        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, None, 45)     0           conv1d_38[0][0]                  \n",
      "                                                                 spatial_dropout1d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, None, 45)     30420       add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, 45)     0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_26 (SpatialDr (None, None, 45)     0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, 45)     0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_27 (SpatialDr (None, None, 45)     0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, None, 45)     2070        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, None, 45)     0           conv1d_41[0][0]                  \n",
      "                                                                 spatial_dropout1d_27[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, None, 45)     30420       add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, 45)     0           conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_28 (SpatialDr (None, None, 45)     0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, 45)     0           conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_29 (SpatialDr (None, None, 45)     0           activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, None, 45)     2070        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, None, 45)     0           conv1d_44[0][0]                  \n",
      "                                                                 spatial_dropout1d_29[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, None, 45)     30420       add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, 45)     0           conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_30 (SpatialDr (None, None, 45)     0           activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, 45)     0           conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_31 (SpatialDr (None, None, 45)     0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, None, 45)     2070        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, None, 45)     0           conv1d_47[0][0]                  \n",
      "                                                                 spatial_dropout1d_31[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, None, 45)     30420       add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, None, 45)     0           conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_32 (SpatialDr (None, None, 45)     0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, None, 45)     0           conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_33 (SpatialDr (None, None, 45)     0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, None, 45)     2070        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, None, 45)     0           conv1d_50[0][0]                  \n",
      "                                                                 spatial_dropout1d_33[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, None, 45)     30420       add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, None, 45)     0           conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_34 (SpatialDr (None, None, 45)     0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_34[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, 45)     0           conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_35 (SpatialDr (None, None, 45)     0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, None, 45)     2070        add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, None, 45)     0           conv1d_53[0][0]                  \n",
      "                                                                 spatial_dropout1d_35[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, None, 45)     30420       add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, 45)     0           conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_36 (SpatialDr (None, None, 45)     0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_36[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, 45)     0           conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_37 (SpatialDr (None, None, 45)     0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, None, 45)     2070        add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, None, 45)     0           conv1d_56[0][0]                  \n",
      "                                                                 spatial_dropout1d_37[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, None, 45)     30420       add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, 45)     0           conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_38 (SpatialDr (None, None, 45)     0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_38[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, 45)     0           conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_39 (SpatialDr (None, None, 45)     0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, None, 45)     0           spatial_dropout1d_21[0][0]       \n",
      "                                                                 spatial_dropout1d_23[0][0]       \n",
      "                                                                 spatial_dropout1d_25[0][0]       \n",
      "                                                                 spatial_dropout1d_27[0][0]       \n",
      "                                                                 spatial_dropout1d_29[0][0]       \n",
      "                                                                 spatial_dropout1d_31[0][0]       \n",
      "                                                                 spatial_dropout1d_33[0][0]       \n",
      "                                                                 spatial_dropout1d_35[0][0]       \n",
      "                                                                 spatial_dropout1d_37[0][0]       \n",
      "                                                                 spatial_dropout1d_39[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, None, 1)      46          add_21[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 596,836\n",
      "Trainable params: 596,836\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0026WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 2/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0026WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 3/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0025WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 4/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0025WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 5/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0025WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 6/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0025WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 7/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0025WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 8/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0025WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 9/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0024WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 10/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0025WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 11/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0024WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 12/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0025WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 13/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0023WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 14/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0024WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 15/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0023WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 16/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0023WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 17/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0023WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 18/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0023WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 19/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0023WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 20/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0022WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 21/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0023WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 22/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0023WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 23/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0022WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 24/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0023WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 25/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0022WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 26/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0022WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 27/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0022WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 28/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0023WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 29/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0022WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 30/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0022WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 31/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0020WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 32/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0022WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 33/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0023WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 34/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0023WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 35/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0023WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 36/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0021WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 37/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0021WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "loading previous model:\n",
      " models/f:45|k:15|d:1x2x4x8x16|s:2|bs:20|c_len:2|w_snr:8|c_buf:10|c_shp:gauss|c_amp:1|f_low:1|f_hig:10|r_smp:40|cmpts:ZNE|lr:1.1111111111111112e-05|pat:6|time:20-06-25-22-19-32|w_len:180.h5\n",
      "Receptive Field Length: 10.85 seconds\n",
      "building new model:\n",
      " models/f:45|k:15|d:1x2x4x8x16|s:2|bs:20|c_len:2|w_snr:5|c_buf:10|c_shp:gauss|c_amp:1|f_low:1|f_hig:10|r_smp:40|cmpts:ZNE|lr:3.7037037037037037e-06|pat:9|time:20-06-25-22-35-06|w_len:180\n",
      "Receptive Field Length: 10.85 seconds\n",
      "Model: \"encoder_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, None, 45)     2070        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, 45)     0           conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_40 (SpatialDr (None, None, 45)     0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_40[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, 45)     0           conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_41 (SpatialDr (None, None, 45)     0           activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, None, 45)     180         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, None, 45)     0           conv1d_62[0][0]                  \n",
      "                                                                 spatial_dropout1d_41[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, None, 45)     30420       add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, 45)     0           conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_42 (SpatialDr (None, None, 45)     0           activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_42[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, 45)     0           conv1d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_43 (SpatialDr (None, None, 45)     0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, None, 45)     2070        add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, None, 45)     0           conv1d_65[0][0]                  \n",
      "                                                                 spatial_dropout1d_43[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_66 (Conv1D)              (None, None, 45)     30420       add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, 45)     0           conv1d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_44 (SpatialDr (None, None, 45)     0           activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_67 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_44[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, 45)     0           conv1d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_45 (SpatialDr (None, None, 45)     0           activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_68 (Conv1D)              (None, None, 45)     2070        add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, None, 45)     0           conv1d_68[0][0]                  \n",
      "                                                                 spatial_dropout1d_45[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_69 (Conv1D)              (None, None, 45)     30420       add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, 45)     0           conv1d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_46 (SpatialDr (None, None, 45)     0           activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_70 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_46[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, 45)     0           conv1d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_47 (SpatialDr (None, None, 45)     0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_71 (Conv1D)              (None, None, 45)     2070        add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, None, 45)     0           conv1d_71[0][0]                  \n",
      "                                                                 spatial_dropout1d_47[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_72 (Conv1D)              (None, None, 45)     30420       add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, 45)     0           conv1d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_48 (SpatialDr (None, None, 45)     0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_73 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_48[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, 45)     0           conv1d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_49 (SpatialDr (None, None, 45)     0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_74 (Conv1D)              (None, None, 45)     2070        add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, None, 45)     0           conv1d_74[0][0]                  \n",
      "                                                                 spatial_dropout1d_49[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_75 (Conv1D)              (None, None, 45)     30420       add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, 45)     0           conv1d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_50 (SpatialDr (None, None, 45)     0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_76 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_50[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, 45)     0           conv1d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_51 (SpatialDr (None, None, 45)     0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_77 (Conv1D)              (None, None, 45)     2070        add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, None, 45)     0           conv1d_77[0][0]                  \n",
      "                                                                 spatial_dropout1d_51[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_78 (Conv1D)              (None, None, 45)     30420       add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, 45)     0           conv1d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_52 (SpatialDr (None, None, 45)     0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_79 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_52[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, 45)     0           conv1d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_53 (SpatialDr (None, None, 45)     0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_80 (Conv1D)              (None, None, 45)     2070        add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, None, 45)     0           conv1d_80[0][0]                  \n",
      "                                                                 spatial_dropout1d_53[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_81 (Conv1D)              (None, None, 45)     30420       add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, 45)     0           conv1d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_54 (SpatialDr (None, None, 45)     0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_82 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_54[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, None, 45)     0           conv1d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_55 (SpatialDr (None, None, 45)     0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_83 (Conv1D)              (None, None, 45)     2070        add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, None, 45)     0           conv1d_83[0][0]                  \n",
      "                                                                 spatial_dropout1d_55[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_84 (Conv1D)              (None, None, 45)     30420       add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, None, 45)     0           conv1d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_56 (SpatialDr (None, None, 45)     0           activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_85 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_56[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, None, 45)     0           conv1d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_57 (SpatialDr (None, None, 45)     0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_86 (Conv1D)              (None, None, 45)     2070        add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, None, 45)     0           conv1d_86[0][0]                  \n",
      "                                                                 spatial_dropout1d_57[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_87 (Conv1D)              (None, None, 45)     30420       add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, None, 45)     0           conv1d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_58 (SpatialDr (None, None, 45)     0           activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_88 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_58[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, None, 45)     0           conv1d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_59 (SpatialDr (None, None, 45)     0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, None, 45)     0           spatial_dropout1d_41[0][0]       \n",
      "                                                                 spatial_dropout1d_43[0][0]       \n",
      "                                                                 spatial_dropout1d_45[0][0]       \n",
      "                                                                 spatial_dropout1d_47[0][0]       \n",
      "                                                                 spatial_dropout1d_49[0][0]       \n",
      "                                                                 spatial_dropout1d_51[0][0]       \n",
      "                                                                 spatial_dropout1d_53[0][0]       \n",
      "                                                                 spatial_dropout1d_55[0][0]       \n",
      "                                                                 spatial_dropout1d_57[0][0]       \n",
      "                                                                 spatial_dropout1d_59[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, None, 1)      46          add_32[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 596,836\n",
      "Trainable params: 596,836\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0024WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 2/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0025WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 3/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0025WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 4/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0027WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 5/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0026WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 6/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0026WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 7/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0025WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 8/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0025WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 9/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0026WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 10/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0027WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 11/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0025WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 12/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0026WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 13/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0027WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 14/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0024WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 15/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0026WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 16/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0025WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 17/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0024WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "loading previous model:\n",
      " models/f:45|k:15|d:1x2x4x8x16|s:2|bs:20|c_len:2|w_snr:5|c_buf:10|c_shp:gauss|c_amp:1|f_low:1|f_hig:10|r_smp:40|cmpts:ZNE|lr:3.7037037037037037e-06|pat:9|time:20-06-25-22-35-06|w_len:180.h5\n",
      "Receptive Field Length: 10.85 seconds\n",
      "building new model:\n",
      " models/f:45|k:15|d:1x2x4x8x16|s:2|bs:20|c_len:2|w_snr:3|c_buf:10|c_shp:gauss|c_amp:1|f_low:1|f_hig:10|r_smp:40|cmpts:ZNE|lr:1.234567901234568e-06|pat:12|time:20-06-25-22-42-23|w_len:180\n",
      "Receptive Field Length: 10.85 seconds\n",
      "Model: \"encoder_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_90 (Conv1D)              (None, None, 45)     2070        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, None, 45)     0           conv1d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_60 (SpatialDr (None, None, 45)     0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_91 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_60[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, None, 45)     0           conv1d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_61 (SpatialDr (None, None, 45)     0           activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_92 (Conv1D)              (None, None, 45)     180         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, None, 45)     0           conv1d_92[0][0]                  \n",
      "                                                                 spatial_dropout1d_61[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_93 (Conv1D)              (None, None, 45)     30420       add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, None, 45)     0           conv1d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_62 (SpatialDr (None, None, 45)     0           activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_94 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_62[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, 45)     0           conv1d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_63 (SpatialDr (None, None, 45)     0           activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_95 (Conv1D)              (None, None, 45)     2070        add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, None, 45)     0           conv1d_95[0][0]                  \n",
      "                                                                 spatial_dropout1d_63[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_96 (Conv1D)              (None, None, 45)     30420       add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, 45)     0           conv1d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_64 (SpatialDr (None, None, 45)     0           activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_97 (Conv1D)              (None, None, 45)     30420       spatial_dropout1d_64[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, 45)     0           conv1d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_65 (SpatialDr (None, None, 45)     0           activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_98 (Conv1D)              (None, None, 45)     2070        add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, None, 45)     0           conv1d_98[0][0]                  \n",
      "                                                                 spatial_dropout1d_65[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_99 (Conv1D)              (None, None, 45)     30420       add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, None, 45)     0           conv1d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_66 (SpatialDr (None, None, 45)     0           activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_100 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_66[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, None, 45)     0           conv1d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_67 (SpatialDr (None, None, 45)     0           activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_101 (Conv1D)             (None, None, 45)     2070        add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, None, 45)     0           conv1d_101[0][0]                 \n",
      "                                                                 spatial_dropout1d_67[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_102 (Conv1D)             (None, None, 45)     30420       add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, None, 45)     0           conv1d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_68 (SpatialDr (None, None, 45)     0           activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_103 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_68[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, None, 45)     0           conv1d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_69 (SpatialDr (None, None, 45)     0           activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_104 (Conv1D)             (None, None, 45)     2070        add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, None, 45)     0           conv1d_104[0][0]                 \n",
      "                                                                 spatial_dropout1d_69[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_105 (Conv1D)             (None, None, 45)     30420       add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, None, 45)     0           conv1d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_70 (SpatialDr (None, None, 45)     0           activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_106 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_70[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, None, 45)     0           conv1d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_71 (SpatialDr (None, None, 45)     0           activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_107 (Conv1D)             (None, None, 45)     2070        add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, None, 45)     0           conv1d_107[0][0]                 \n",
      "                                                                 spatial_dropout1d_71[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_108 (Conv1D)             (None, None, 45)     30420       add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, None, 45)     0           conv1d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_72 (SpatialDr (None, None, 45)     0           activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_109 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_72[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, None, 45)     0           conv1d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_73 (SpatialDr (None, None, 45)     0           activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_110 (Conv1D)             (None, None, 45)     2070        add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, None, 45)     0           conv1d_110[0][0]                 \n",
      "                                                                 spatial_dropout1d_73[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_111 (Conv1D)             (None, None, 45)     30420       add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, None, 45)     0           conv1d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_74 (SpatialDr (None, None, 45)     0           activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_112 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_74[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, None, 45)     0           conv1d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_75 (SpatialDr (None, None, 45)     0           activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_113 (Conv1D)             (None, None, 45)     2070        add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, None, 45)     0           conv1d_113[0][0]                 \n",
      "                                                                 spatial_dropout1d_75[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_114 (Conv1D)             (None, None, 45)     30420       add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, None, 45)     0           conv1d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_76 (SpatialDr (None, None, 45)     0           activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_115 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_76[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, None, 45)     0           conv1d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_77 (SpatialDr (None, None, 45)     0           activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_116 (Conv1D)             (None, None, 45)     2070        add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, None, 45)     0           conv1d_116[0][0]                 \n",
      "                                                                 spatial_dropout1d_77[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_117 (Conv1D)             (None, None, 45)     30420       add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, None, 45)     0           conv1d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_78 (SpatialDr (None, None, 45)     0           activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_118 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_78[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, None, 45)     0           conv1d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_79 (SpatialDr (None, None, 45)     0           activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, None, 45)     0           spatial_dropout1d_61[0][0]       \n",
      "                                                                 spatial_dropout1d_63[0][0]       \n",
      "                                                                 spatial_dropout1d_65[0][0]       \n",
      "                                                                 spatial_dropout1d_67[0][0]       \n",
      "                                                                 spatial_dropout1d_69[0][0]       \n",
      "                                                                 spatial_dropout1d_71[0][0]       \n",
      "                                                                 spatial_dropout1d_73[0][0]       \n",
      "                                                                 spatial_dropout1d_75[0][0]       \n",
      "                                                                 spatial_dropout1d_77[0][0]       \n",
      "                                                                 spatial_dropout1d_79[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, None, 1)      46          add_43[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 596,836\n",
      "Trainable params: 596,836\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 2/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 3/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 4/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 5/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 6/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 7/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 8/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 9/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 10/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 11/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 12/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 13/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 14/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0028WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 15/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 16/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 17/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 18/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 19/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 20/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 21/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 22/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0028WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "loading previous model:\n",
      " models/f:45|k:15|d:1x2x4x8x16|s:2|bs:20|c_len:2|w_snr:3|c_buf:10|c_shp:gauss|c_amp:1|f_low:1|f_hig:10|r_smp:40|cmpts:ZNE|lr:1.234567901234568e-06|pat:12|time:20-06-25-22-42-23|w_len:180.h5\n",
      "Receptive Field Length: 10.85 seconds\n",
      "building new model:\n",
      " models/f:45|k:15|d:1x2x4x8x16|s:2|bs:20|c_len:2|w_snr:2|c_buf:10|c_shp:gauss|c_amp:1|f_low:1|f_hig:10|r_smp:40|cmpts:ZNE|lr:4.11522633744856e-07|pat:15|time:20-06-25-22-51-52|w_len:180\n",
      "Receptive Field Length: 10.85 seconds\n",
      "Model: \"encoder_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_120 (Conv1D)             (None, None, 45)     2070        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, None, 45)     0           conv1d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_80 (SpatialDr (None, None, 45)     0           activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_121 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_80[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, None, 45)     0           conv1d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_81 (SpatialDr (None, None, 45)     0           activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_122 (Conv1D)             (None, None, 45)     180         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, None, 45)     0           conv1d_122[0][0]                 \n",
      "                                                                 spatial_dropout1d_81[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_123 (Conv1D)             (None, None, 45)     30420       add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, None, 45)     0           conv1d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_82 (SpatialDr (None, None, 45)     0           activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_124 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_82[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, None, 45)     0           conv1d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_83 (SpatialDr (None, None, 45)     0           activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_125 (Conv1D)             (None, None, 45)     2070        add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, None, 45)     0           conv1d_125[0][0]                 \n",
      "                                                                 spatial_dropout1d_83[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_126 (Conv1D)             (None, None, 45)     30420       add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, None, 45)     0           conv1d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_84 (SpatialDr (None, None, 45)     0           activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_127 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_84[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, None, 45)     0           conv1d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_85 (SpatialDr (None, None, 45)     0           activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_128 (Conv1D)             (None, None, 45)     2070        add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, None, 45)     0           conv1d_128[0][0]                 \n",
      "                                                                 spatial_dropout1d_85[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_129 (Conv1D)             (None, None, 45)     30420       add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, None, 45)     0           conv1d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_86 (SpatialDr (None, None, 45)     0           activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_130 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_86[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, None, 45)     0           conv1d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_87 (SpatialDr (None, None, 45)     0           activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_131 (Conv1D)             (None, None, 45)     2070        add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, None, 45)     0           conv1d_131[0][0]                 \n",
      "                                                                 spatial_dropout1d_87[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_132 (Conv1D)             (None, None, 45)     30420       add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, None, 45)     0           conv1d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_88 (SpatialDr (None, None, 45)     0           activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_133 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_88[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, None, 45)     0           conv1d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_89 (SpatialDr (None, None, 45)     0           activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_134 (Conv1D)             (None, None, 45)     2070        add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, None, 45)     0           conv1d_134[0][0]                 \n",
      "                                                                 spatial_dropout1d_89[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_135 (Conv1D)             (None, None, 45)     30420       add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, None, 45)     0           conv1d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_90 (SpatialDr (None, None, 45)     0           activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_136 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_90[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, None, 45)     0           conv1d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_91 (SpatialDr (None, None, 45)     0           activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_137 (Conv1D)             (None, None, 45)     2070        add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_49 (Add)                    (None, None, 45)     0           conv1d_137[0][0]                 \n",
      "                                                                 spatial_dropout1d_91[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_138 (Conv1D)             (None, None, 45)     30420       add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, None, 45)     0           conv1d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_92 (SpatialDr (None, None, 45)     0           activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_139 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_92[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, None, 45)     0           conv1d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_93 (SpatialDr (None, None, 45)     0           activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_140 (Conv1D)             (None, None, 45)     2070        add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_50 (Add)                    (None, None, 45)     0           conv1d_140[0][0]                 \n",
      "                                                                 spatial_dropout1d_93[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_141 (Conv1D)             (None, None, 45)     30420       add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, None, 45)     0           conv1d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_94 (SpatialDr (None, None, 45)     0           activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_142 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_94[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, None, 45)     0           conv1d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_95 (SpatialDr (None, None, 45)     0           activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_143 (Conv1D)             (None, None, 45)     2070        add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, None, 45)     0           conv1d_143[0][0]                 \n",
      "                                                                 spatial_dropout1d_95[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_144 (Conv1D)             (None, None, 45)     30420       add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, None, 45)     0           conv1d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_96 (SpatialDr (None, None, 45)     0           activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_145 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_96[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, None, 45)     0           conv1d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_97 (SpatialDr (None, None, 45)     0           activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_146 (Conv1D)             (None, None, 45)     2070        add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_52 (Add)                    (None, None, 45)     0           conv1d_146[0][0]                 \n",
      "                                                                 spatial_dropout1d_97[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_147 (Conv1D)             (None, None, 45)     30420       add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, None, 45)     0           conv1d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_98 (SpatialDr (None, None, 45)     0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_148 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_98[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, None, 45)     0           conv1d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_99 (SpatialDr (None, None, 45)     0           activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_54 (Add)                    (None, None, 45)     0           spatial_dropout1d_81[0][0]       \n",
      "                                                                 spatial_dropout1d_83[0][0]       \n",
      "                                                                 spatial_dropout1d_85[0][0]       \n",
      "                                                                 spatial_dropout1d_87[0][0]       \n",
      "                                                                 spatial_dropout1d_89[0][0]       \n",
      "                                                                 spatial_dropout1d_91[0][0]       \n",
      "                                                                 spatial_dropout1d_93[0][0]       \n",
      "                                                                 spatial_dropout1d_95[0][0]       \n",
      "                                                                 spatial_dropout1d_97[0][0]       \n",
      "                                                                 spatial_dropout1d_99[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, None, 1)      46          add_54[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 596,836\n",
      "Trainable params: 596,836\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 2/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 3/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 4/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 5/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 6/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 7/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 8/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 9/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0033WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 10/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 11/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0032WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 12/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0032WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 13/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 14/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 15/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0032WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 16/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 17/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 18/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 19/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 20/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 21/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 22/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 23/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 24/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 25/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0032WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 26/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 27/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 28/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 29/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0032WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 30/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0032WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 31/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 32/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 33/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 34/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 35/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 36/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 37/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 38/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0032WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 39/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 40/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 41/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 42/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 43/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 44/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 45/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 46/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 47/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 48/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 50/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "loading previous model:\n",
      " models/f:45|k:15|d:1x2x4x8x16|s:2|bs:20|c_len:2|w_snr:2|c_buf:10|c_shp:gauss|c_amp:1|f_low:1|f_hig:10|r_smp:40|cmpts:ZNE|lr:4.11522633744856e-07|pat:15|time:20-06-25-22-51-52|w_len:180.h5\n",
      "Receptive Field Length: 10.85 seconds\n",
      "building new model:\n",
      " models/f:45|k:15|d:1x2x4x8x16|s:2|bs:20|c_len:2|w_snr:1|c_buf:10|c_shp:gauss|c_amp:1|f_low:1|f_hig:10|r_smp:40|cmpts:ZNE|lr:1.3717421124828532e-07|pat:18|time:20-06-25-23-13-18|w_len:180\n",
      "Receptive Field Length: 10.85 seconds\n",
      "Model: \"encoder_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_150 (Conv1D)             (None, None, 45)     2070        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, None, 45)     0           conv1d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_100 (SpatialD (None, None, 45)     0           activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_151 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_100[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, None, 45)     0           conv1d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_101 (SpatialD (None, None, 45)     0           activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_152 (Conv1D)             (None, None, 45)     180         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_55 (Add)                    (None, None, 45)     0           conv1d_152[0][0]                 \n",
      "                                                                 spatial_dropout1d_101[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_153 (Conv1D)             (None, None, 45)     30420       add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, None, 45)     0           conv1d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_102 (SpatialD (None, None, 45)     0           activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_154 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_102[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, None, 45)     0           conv1d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_103 (SpatialD (None, None, 45)     0           activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_155 (Conv1D)             (None, None, 45)     2070        add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_56 (Add)                    (None, None, 45)     0           conv1d_155[0][0]                 \n",
      "                                                                 spatial_dropout1d_103[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_156 (Conv1D)             (None, None, 45)     30420       add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, None, 45)     0           conv1d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_104 (SpatialD (None, None, 45)     0           activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_157 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_104[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, None, 45)     0           conv1d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_105 (SpatialD (None, None, 45)     0           activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_158 (Conv1D)             (None, None, 45)     2070        add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_57 (Add)                    (None, None, 45)     0           conv1d_158[0][0]                 \n",
      "                                                                 spatial_dropout1d_105[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_159 (Conv1D)             (None, None, 45)     30420       add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, None, 45)     0           conv1d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_106 (SpatialD (None, None, 45)     0           activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_160 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_106[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, None, 45)     0           conv1d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_107 (SpatialD (None, None, 45)     0           activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_161 (Conv1D)             (None, None, 45)     2070        add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_58 (Add)                    (None, None, 45)     0           conv1d_161[0][0]                 \n",
      "                                                                 spatial_dropout1d_107[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_162 (Conv1D)             (None, None, 45)     30420       add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, None, 45)     0           conv1d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_108 (SpatialD (None, None, 45)     0           activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_163 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_108[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, None, 45)     0           conv1d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_109 (SpatialD (None, None, 45)     0           activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_164 (Conv1D)             (None, None, 45)     2070        add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_59 (Add)                    (None, None, 45)     0           conv1d_164[0][0]                 \n",
      "                                                                 spatial_dropout1d_109[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_165 (Conv1D)             (None, None, 45)     30420       add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, None, 45)     0           conv1d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_110 (SpatialD (None, None, 45)     0           activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_166 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_110[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, None, 45)     0           conv1d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_111 (SpatialD (None, None, 45)     0           activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_167 (Conv1D)             (None, None, 45)     2070        add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_60 (Add)                    (None, None, 45)     0           conv1d_167[0][0]                 \n",
      "                                                                 spatial_dropout1d_111[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_168 (Conv1D)             (None, None, 45)     30420       add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, None, 45)     0           conv1d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_112 (SpatialD (None, None, 45)     0           activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_169 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_112[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, None, 45)     0           conv1d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_113 (SpatialD (None, None, 45)     0           activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_170 (Conv1D)             (None, None, 45)     2070        add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_61 (Add)                    (None, None, 45)     0           conv1d_170[0][0]                 \n",
      "                                                                 spatial_dropout1d_113[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_171 (Conv1D)             (None, None, 45)     30420       add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, None, 45)     0           conv1d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_114 (SpatialD (None, None, 45)     0           activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_172 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_114[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, None, 45)     0           conv1d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_115 (SpatialD (None, None, 45)     0           activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_173 (Conv1D)             (None, None, 45)     2070        add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_62 (Add)                    (None, None, 45)     0           conv1d_173[0][0]                 \n",
      "                                                                 spatial_dropout1d_115[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_174 (Conv1D)             (None, None, 45)     30420       add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, None, 45)     0           conv1d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_116 (SpatialD (None, None, 45)     0           activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_175 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_116[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, None, 45)     0           conv1d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_117 (SpatialD (None, None, 45)     0           activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_176 (Conv1D)             (None, None, 45)     2070        add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_63 (Add)                    (None, None, 45)     0           conv1d_176[0][0]                 \n",
      "                                                                 spatial_dropout1d_117[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_177 (Conv1D)             (None, None, 45)     30420       add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, None, 45)     0           conv1d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_118 (SpatialD (None, None, 45)     0           activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_178 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_118[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, None, 45)     0           conv1d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_119 (SpatialD (None, None, 45)     0           activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_65 (Add)                    (None, None, 45)     0           spatial_dropout1d_101[0][0]      \n",
      "                                                                 spatial_dropout1d_103[0][0]      \n",
      "                                                                 spatial_dropout1d_105[0][0]      \n",
      "                                                                 spatial_dropout1d_107[0][0]      \n",
      "                                                                 spatial_dropout1d_109[0][0]      \n",
      "                                                                 spatial_dropout1d_111[0][0]      \n",
      "                                                                 spatial_dropout1d_113[0][0]      \n",
      "                                                                 spatial_dropout1d_115[0][0]      \n",
      "                                                                 spatial_dropout1d_117[0][0]      \n",
      "                                                                 spatial_dropout1d_119[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, None, 1)      46          add_65[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 596,836\n",
      "Trainable params: 596,836\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 2/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0032WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 3/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0032WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 4/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0032WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 5/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 6/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 7/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0028WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 8/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 9/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 10/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 11/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 12/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 13/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 14/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0032WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 15/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 16/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0032WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 17/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 18/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 19/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 20/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 21/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 22/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 23/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0032WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 24/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 25/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 26/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0033WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 27/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0032WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 28/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 29/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 30/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 31/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 32/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 33/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 0.0030 - val_loss: 0.0034\n",
      "loading previous model:\n",
      " models/f:45|k:15|d:1x2x4x8x16|s:2|bs:20|c_len:2|w_snr:1|c_buf:10|c_shp:gauss|c_amp:1|f_low:1|f_hig:10|r_smp:40|cmpts:ZNE|lr:1.3717421124828532e-07|pat:18|time:20-06-25-23-13-18|w_len:180.h5\n",
      "Receptive Field Length: 10.85 seconds\n",
      "building new model:\n",
      " models/f:45|k:15|d:1x2x4x8x16|s:2|bs:20|c_len:2|w_snr:0|c_buf:10|c_shp:gauss|c_amp:1|f_low:1|f_hig:10|r_smp:40|cmpts:ZNE|lr:4.5724737082761776e-08|pat:21|time:20-06-25-23-27-43|w_len:180\n",
      "Receptive Field Length: 10.85 seconds\n",
      "Model: \"encoder_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_180 (Conv1D)             (None, None, 45)     2070        input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, None, 45)     0           conv1d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_120 (SpatialD (None, None, 45)     0           activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_181 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_120[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, None, 45)     0           conv1d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_121 (SpatialD (None, None, 45)     0           activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_182 (Conv1D)             (None, None, 45)     180         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_66 (Add)                    (None, None, 45)     0           conv1d_182[0][0]                 \n",
      "                                                                 spatial_dropout1d_121[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_183 (Conv1D)             (None, None, 45)     30420       add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, None, 45)     0           conv1d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_122 (SpatialD (None, None, 45)     0           activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_184 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_122[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, None, 45)     0           conv1d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_123 (SpatialD (None, None, 45)     0           activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_185 (Conv1D)             (None, None, 45)     2070        add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_67 (Add)                    (None, None, 45)     0           conv1d_185[0][0]                 \n",
      "                                                                 spatial_dropout1d_123[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_186 (Conv1D)             (None, None, 45)     30420       add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, None, 45)     0           conv1d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_124 (SpatialD (None, None, 45)     0           activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_187 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_124[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, None, 45)     0           conv1d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_125 (SpatialD (None, None, 45)     0           activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_188 (Conv1D)             (None, None, 45)     2070        add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_68 (Add)                    (None, None, 45)     0           conv1d_188[0][0]                 \n",
      "                                                                 spatial_dropout1d_125[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_189 (Conv1D)             (None, None, 45)     30420       add_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, None, 45)     0           conv1d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_126 (SpatialD (None, None, 45)     0           activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_190 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_126[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, None, 45)     0           conv1d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_127 (SpatialD (None, None, 45)     0           activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_191 (Conv1D)             (None, None, 45)     2070        add_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_69 (Add)                    (None, None, 45)     0           conv1d_191[0][0]                 \n",
      "                                                                 spatial_dropout1d_127[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_192 (Conv1D)             (None, None, 45)     30420       add_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, None, 45)     0           conv1d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_128 (SpatialD (None, None, 45)     0           activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_193 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_128[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, None, 45)     0           conv1d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_129 (SpatialD (None, None, 45)     0           activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_194 (Conv1D)             (None, None, 45)     2070        add_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_70 (Add)                    (None, None, 45)     0           conv1d_194[0][0]                 \n",
      "                                                                 spatial_dropout1d_129[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_195 (Conv1D)             (None, None, 45)     30420       add_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, None, 45)     0           conv1d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_130 (SpatialD (None, None, 45)     0           activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_196 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_130[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, None, 45)     0           conv1d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_131 (SpatialD (None, None, 45)     0           activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_197 (Conv1D)             (None, None, 45)     2070        add_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_71 (Add)                    (None, None, 45)     0           conv1d_197[0][0]                 \n",
      "                                                                 spatial_dropout1d_131[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_198 (Conv1D)             (None, None, 45)     30420       add_71[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, None, 45)     0           conv1d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_132 (SpatialD (None, None, 45)     0           activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_199 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_132[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, None, 45)     0           conv1d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_133 (SpatialD (None, None, 45)     0           activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_200 (Conv1D)             (None, None, 45)     2070        add_71[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_72 (Add)                    (None, None, 45)     0           conv1d_200[0][0]                 \n",
      "                                                                 spatial_dropout1d_133[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_201 (Conv1D)             (None, None, 45)     30420       add_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, None, 45)     0           conv1d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_134 (SpatialD (None, None, 45)     0           activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_202 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_134[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, None, 45)     0           conv1d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_135 (SpatialD (None, None, 45)     0           activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_203 (Conv1D)             (None, None, 45)     2070        add_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_73 (Add)                    (None, None, 45)     0           conv1d_203[0][0]                 \n",
      "                                                                 spatial_dropout1d_135[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_204 (Conv1D)             (None, None, 45)     30420       add_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, None, 45)     0           conv1d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_136 (SpatialD (None, None, 45)     0           activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_205 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_136[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, None, 45)     0           conv1d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_137 (SpatialD (None, None, 45)     0           activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_206 (Conv1D)             (None, None, 45)     2070        add_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_74 (Add)                    (None, None, 45)     0           conv1d_206[0][0]                 \n",
      "                                                                 spatial_dropout1d_137[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_207 (Conv1D)             (None, None, 45)     30420       add_74[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, None, 45)     0           conv1d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_138 (SpatialD (None, None, 45)     0           activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_208 (Conv1D)             (None, None, 45)     30420       spatial_dropout1d_138[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, None, 45)     0           conv1d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_139 (SpatialD (None, None, 45)     0           activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_76 (Add)                    (None, None, 45)     0           spatial_dropout1d_121[0][0]      \n",
      "                                                                 spatial_dropout1d_123[0][0]      \n",
      "                                                                 spatial_dropout1d_125[0][0]      \n",
      "                                                                 spatial_dropout1d_127[0][0]      \n",
      "                                                                 spatial_dropout1d_129[0][0]      \n",
      "                                                                 spatial_dropout1d_131[0][0]      \n",
      "                                                                 spatial_dropout1d_133[0][0]      \n",
      "                                                                 spatial_dropout1d_135[0][0]      \n",
      "                                                                 spatial_dropout1d_137[0][0]      \n",
      "                                                                 spatial_dropout1d_139[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, None, 1)      46          add_76[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 596,836\n",
      "Trainable params: 596,836\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 2/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0032WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 3/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0033WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 4/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 5/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 6/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 7/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 8/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 9/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 10/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 11/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0029WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 12/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0032WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 13/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 14/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0032WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 15/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 16/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 17/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 18/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 19/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 20/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 21/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 22/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 23/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 24/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 25/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 26/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 27/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 28/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 29/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 30/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 31/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0032WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 32/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 33/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 34/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0032WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 35/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 36/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 37/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0032WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 38/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 39/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 40/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 41/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 42/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 43/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 44/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 45/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0033WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 46/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 47/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0030WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 48/50\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0032WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0031WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "loading previous model:\n",
      " models/f:45|k:15|d:1x2x4x8x16|s:2|bs:20|c_len:2|w_snr:0|c_buf:10|c_shp:gauss|c_amp:1|f_low:1|f_hig:10|r_smp:40|cmpts:ZNE|lr:4.5724737082761776e-08|pat:21|time:20-06-25-23-27-43|w_len:180.h5\n",
      "Receptive Field Length: 10.85 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdict = {}\n",
    "pdict['f']     = 45\n",
    "pdict['k']     = 15\n",
    "pdict['d']     = [1, 2, 4, 8, 16]\n",
    "pdict['s']     = 2\n",
    "\n",
    "pdict['bs']    = 20\n",
    "pdict['c_len'] = 2\n",
    "pdict['w_snr'] = 10\n",
    "pdict['c_buf'] = 10\n",
    "pdict['c_shp'] = 'gauss'\n",
    "pdict['c_amp'] = 1\n",
    "pdict['f_low'] = 1\n",
    "pdict['f_hig'] = 10\n",
    "pdict['r_smp'] = 40\n",
    "pdict['cmpts'] = 'ZNE'\n",
    "\n",
    "pdict['lr']    = 0.0001\n",
    "pdict['pat']   = 3\n",
    "\n",
    "\n",
    "t_step = 100\n",
    "v_step = 10\n",
    "\n",
    "pdict['pat'] = 0\n",
    "pdict['lr']    = 0.0001\n",
    "\n",
    "my_weights = None\n",
    "# my_weights = model.get_weights()\n",
    "\n",
    "for snr in [10, 8, 5, 3, 2, 1, 0]:\n",
    "    \n",
    "    # instatiate a new model with progressive snr, patience and learning rates\n",
    "    my_time = strftime(\"%y-%m-%d-%H-%M-%S\", localtime())\n",
    "    pdict['time']  = my_time\n",
    "    \n",
    "    pdict['w_snr'] = snr\n",
    "    pdict['pat']   += 3\n",
    "    pdict['lr'] /= 3\n",
    "\n",
    "    pdict['w_len'] = 5*60\n",
    "    gen_val = gen(cat_val, pdict)\n",
    "    \n",
    "    pdict['w_len'] = 3*60\n",
    "    gen_trn = gen(cat_trn, pdict)\n",
    "\n",
    "    model, model_name = load_custom_model(pdict)\n",
    "    model.summary()\n",
    "    \n",
    "    # Load weights from previous model\n",
    "    if my_weights is not None:\n",
    "        model.set_weights(my_weights)\n",
    "    \n",
    "    # Train new model instance\n",
    "    my_hist = model.fit_generator(gen_trn, steps_per_epoch=t_step, epochs=50,\n",
    "                                      validation_data=gen_val, validation_steps=v_step,\n",
    "                                      use_multiprocessing=True,\n",
    "                                      callbacks=get_callbacks(model_name, model_folder, log_folder),\n",
    "                                      workers = 8,\n",
    "                                      max_queue_size=10)\n",
    "    \n",
    "    # Load best model from previous training\n",
    "    pdict = {}\n",
    "    pdict['iniW'] = my_time\n",
    "    model, model_name = load_custom_model(pdict)\n",
    "    pdict = name2param(model_name)\n",
    "    \n",
    "    # Visualize performance of model\n",
    "    XX, YY = next(gen_val)\n",
    "    ZZ = model.predict(XX)\n",
    "    \n",
    "    idx = np.random.randint(pdict['bs'])\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(15,5), sharex=True)\n",
    "    _ = ax[0].plot(XX[idx])\n",
    "    _ = ax[1].plot(YY[idx])\n",
    "    _ = ax[2].plot(ZZ[idx])\n",
    "    plt.savefig(f'snr{snr}.jpg')\n",
    "    plt.clf()\n",
    "    \n",
    "    # Store weights for next iteration of training\n",
    "    my_weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    pdict['w_len'] = 20*60\n",
    "    gen_tst = gen(cat_tst, pdict)\n",
    "    XX, YY = next(gen_tst)\n",
    "    ZZ = model.predict(XX)\n",
    "    \n",
    "    idx = np.random.randint(pdict['bs'])\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(15,5), sharex=True)\n",
    "    _ = ax[0].plot(XX[idx])\n",
    "    _ = ax[1].plot(YY[idx])\n",
    "    _ = ax[2].plot(ZZ[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
