{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71bcd649",
   "metadata": {
    "id": "Su6abpFInE_L",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nArrNet iplements a TCN architecture to create a model that\\nrefines onsite time estimation on seismic waveform picks.\\n\\nThis notebook is a releasable work in progress that shows how to\\ninstantiate the model and perform a 'dummy' inference with the untrained model.\\n\\nNote that ArrNet is a fully convolutional network capable of accepting any \\ninput size.  Care must be taken that the desired features to be excratcted \\nfit within the network's receptive field.  The default settings on this \\nexample have a receptive field of ~30 seconds.\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ArrNet iplements a TCN architecture to create a model that\n",
    "refines onsite time estimation on seismic waveform picks.\n",
    "\n",
    "This notebook is a releasable work in progress that shows how to\n",
    "instantiate the model and perform a 'dummy' inference with the untrained model.\n",
    "\n",
    "Note that ArrNet is a fully convolutional network capable of accepting any \n",
    "input size.  Care must be taken that the desired features to be excratcted \n",
    "fit within the network's receptive field.  The default settings on this \n",
    "example have a receptive field of ~30 seconds.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39ea8f35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4557,
     "status": "ok",
     "timestamp": 1618879149919,
     "user": {
      "displayName": "Raul Pena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0IwP7ua3X2KZHFigiH1lwwODHJJqXWYK0WBF6lw=s64",
      "userId": "08488444859533867855"
     },
     "user_tz": 240
    },
    "id": "N3pQYT7qtdtf",
    "outputId": "f0c2a7dd-6695-4bb4-ac0d-d8ef9ea88307",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/dickey/PycharmProjects/ArrNet\n",
      "Installing collected packages: sdea\n",
      "  Attempting uninstall: sdea\n",
      "    Found existing installation: sdea 0.0.0\n",
      "    Uninstalling sdea-0.0.0:\n",
      "      Successfully uninstalled sdea-0.0.0\n",
      "  Running setup.py develop for sdea\n",
      "Successfully installed sdea\n"
     ]
    }
   ],
   "source": [
    "# If you have downloaded model_utils.py and ArrNet.py to this working directory,\n",
    "# this line will install them for you.\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc2e893c",
   "metadata": {
    "id": "hidden-anniversary",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from ArrNet import ArrNet\n",
    "from model_utils import Params\n",
    "from model_utils import save_dict_to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d54e0a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 474,
     "status": "ok",
     "timestamp": 1618879066156,
     "user": {
      "displayName": "Raul Pena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0IwP7ua3X2KZHFigiH1lwwODHJJqXWYK0WBF6lw=s64",
      "userId": "08488444859533867855"
     },
     "user_tz": 240
    },
    "id": "informal-hawaii",
    "outputId": "0a0c9a68-8a9d-46eb-c709-21aad10c1dce",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr             : 0.001\n",
      "bs             : 1\n",
      "loss           : quantile\n",
      "optimizer      : adam\n",
      "f_1ow          : 0.8\n",
      "f_high         : 4.5\n",
      "f_pad          : 3\n",
      "s_rate         : 40\n",
      "w_len          : 3\n",
      "shift          : 0\n",
      "f              : 5\n",
      "d              : [2, 4, 8]\n",
      "k              : 15\n",
      "s              : 1\n",
      "dense          : [3]\n",
      "pat            : 20\n",
      "t_step         : 1000\n",
      "v_step         : 60\n",
      "cmps           : B\n",
      "project_name   : \n",
      "model_name     : lr:0.001|bs:1|loss:quantile|optimizer:adam|f_1ow:0.8|f_high:4.5|f_pad:3|s_rate:40|w_len:3|shift:0|f:5|d:2x4x8|k:15|s:1|dense:3|pat:20|t_step:1000|v_step:60|cmps:B|trnRET:False|type:tcn|quantiles:0.9772x0.8413x0.1538x0.0228\n",
      "model_file     : \n",
      "model_save     : \n",
      "log_folder     : \n",
      "data_folder    : \n",
      "image_folder   : \n",
      "model_folder   : \n",
      "trnRET         : False\n",
      "catalog        : \n",
      "type           : tcn\n",
      "quantiles      : [0.9772, 0.8413, 0.1538, 0.0228]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the get_default_par method to save a set of default parameters in a json file.\n",
    "# All hyperparameters for the network are controlled by setting values in this par file.\n",
    "\n",
    "params = ArrNet.get_default_par(os.path.join('.', 'test_par.json'))\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c55c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_par(par_file): \n",
    "    '''\n",
    "    Parameters\n",
    "    ------\n",
    "    par_file : model utils.Param\n",
    "        A json file where the default parameters will be saved. Only call this if you dont know\n",
    "        what parameters are needed by the model. You may create your own Param object and\n",
    "        create the model that way if you know the necessary parameters.\n",
    "    Returns\n",
    "    ------\n",
    "    TYPE\n",
    "    Default Param object.\n",
    "    '''\n",
    "\n",
    "    par = { 'lr': 0.001,\n",
    "            'bs': 1,\n",
    "            'loss': 'quantile',\n",
    "            'optimizer':'adam',\n",
    "            'f_1ow': 0.8,\n",
    "            'f_high': 4.5,\n",
    "            'f_pad': 3 ,\n",
    "            's_rate': 40,\n",
    "            'w_len': 3,\n",
    "            'shift': 0,\n",
    "            'f': 5,\n",
    "            'd': [2, 4, 8],\n",
    "            'k': 15,\n",
    "            's': 1,\n",
    "            'dense': [3],\n",
    "            'pat': 20,\n",
    "            't_step': 1000,\n",
    "            'v_step': 60,\n",
    "            'cmps': 'B',\n",
    "            'project_name': '', \n",
    "            'model_name': '', \n",
    "            'model_file': '',\n",
    "            'model_save': '',\n",
    "            'log_folder': '',\n",
    "            'data_folder': '',\n",
    "            'image_folder': '',\n",
    "            'model_folder': '',\n",
    "            'trnRET': False,\n",
    "            'catalog': '',\n",
    "            'type': 'tcn',\n",
    "            'quantiles': [0.9772, 0.8413, 0.1538, 0.0228], }\n",
    "\n",
    "    save_dict_to_json(par, par_file) \n",
    "    return Params(par_file)\n",
    "\n",
    "def residual_block(x, dilation_rate, nb_filters, kernel_size, padding, dropout_rate=0):\n",
    "    prev_x = x\n",
    "    x = tf.keras.layers.Conv1D(filters=nb_filters,\n",
    "                               kernel_size=kernel_size,\n",
    "                               dilation_rate=dilation_rate,\n",
    "                               padding=padding)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.SpatialDropout1D(rate=dropout_rate)(x)\n",
    "\n",
    "    # lxl conv to match the shapes (channel dimension)\n",
    "    prev_x = tf.keras.layers.Conv1D(nb_filters, 1, padding='same')(prev_x) \n",
    "    res_x = tf.keras.layers.add([prev_x, x])\n",
    "    return res_x, x   \n",
    "\n",
    "\n",
    "def get_loss(q):\n",
    "\n",
    "    def quantile_loss(q, y_p, y):\n",
    "        e = y_p-y\n",
    "        return tf.keras.backend.mean(tf.math.maximum(q*e, (q-1)*e))\n",
    "\n",
    "    def q_loss(y_true, y_pred):\n",
    "        return quantile_loss(q, y_true, y_pred) \n",
    "\n",
    "    return q_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26397a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "par = params\n",
    "padding = 'causal'\n",
    "drop = 0.05\n",
    "nb_chan = len(par.cmps)\n",
    "nb_filters = par.f\n",
    "filter_len = par.k\n",
    "dilations = par.d\n",
    "nb_stacks = par.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a394b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.keras.layers.Input(shape=(None, nb_chan))\n",
    "x = input_layer\n",
    "skip_connections = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "737e389b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2\n",
      "0 4\n",
      "0 8\n"
     ]
    }
   ],
   "source": [
    "for s in range(nb_stacks):\n",
    "    for d in dilations:\n",
    "        print(s, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1a2dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for s in range(nb_stacks):\n",
    "    for d in dilations:\n",
    "        x, skip_out = residual_block(x,\n",
    "                                           dilation_rate=d,\n",
    "                                           nb_filters=nb_filters,\n",
    "                                           kernel_size=filter_len,\n",
    "                                           padding=padding,\n",
    "                                           dropout_rate=drop)\n",
    "\n",
    "        skip_connections.append(skip_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c8013f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x = tf.keras.layers.add(skip_connections)\n",
    "x = tf.keras.layers.Lambda(lambda tt: tt[:, -1, :])(x)\n",
    "\n",
    "for dense in par.dense:\n",
    "    x = tf.keras.layers.Dense(dense, activation='relu')(x)\n",
    "    if (len(par.dense) > 1):\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "if (par.loss == 'quantile'):\n",
    "    loss_array = {} \n",
    "    output_layer = []\n",
    "    out= tf.keras.layers.Dense(1, activation='linear', name='huber')(x)\n",
    "    output_layer.append(out)\n",
    "    loss_array['huber'] = tf.keras.losses.Huber() \n",
    "    for q in par.quantiles:\n",
    "        name= f'output_{int(100*q):02d}'\n",
    "        out= tf.keras.layers.Dense(1, activation='linear', name=name)(x)\n",
    "        output_layer.append(out)\n",
    "\n",
    "        loss_array[name] = get_loss(q)\n",
    "\n",
    "    model = tf.keras.Model(input_layer, output_layer, name='q_model')\n",
    "    model.compile(optimizer=par.optimizer, loss=loss_array, metrics=['mean_absolute_error'])\n",
    "else :\n",
    "    output_layer = tf.keras.layers.Dense(1, activation='linear', name='output')(x)\n",
    "    model = tf.keras.Model(input_layer ,output_layer, name='model') \n",
    "    model.compile(optimizer=par.optimizer, loss=par.loss, metrics=['mean_absolute_error'])\n",
    "return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca581ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c58661d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1979,
     "status": "ok",
     "timestamp": 1618879183749,
     "user": {
      "displayName": "Raul Pena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0IwP7ua3X2KZHFigiH1lwwODHJJqXWYK0WBF6lw=s64",
      "userId": "08488444859533867855"
     },
     "user_tz": 240
    },
    "id": "convertible-rendering",
    "outputId": "9acd2c32-5da5-4d75-eea6-c2bba0e5589a",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a model using the previously created params.\n",
    "# Settings can be adjusted in the parameters by setting the values\n",
    "# Ex. params.lr = 0.0001\n",
    "model = ArrNet.get_network(params)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaa7b60",
   "metadata": {
    "id": "heated-balance"
   },
   "outputs": [],
   "source": [
    "# With the model created, lets make a fake data trace to test it\n",
    "data = np.random.uniform(size=(1,1200,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137e7f3c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 569,
     "status": "ok",
     "timestamp": 1618879348150,
     "user": {
      "displayName": "Raul Pena",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0IwP7ua3X2KZHFigiH1lwwODHJJqXWYK0WBF6lw=s64",
      "userId": "08488444859533867855"
     },
     "user_tz": 240
    },
    "id": "built-direction",
    "outputId": "3cdf94eb-3816-4bca-874b-f036862ed8b9"
   },
   "outputs": [],
   "source": [
    "# The output of this inference corresponds to [0] = y_hat, [1..n] = the chosen percentiles\n",
    "model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9d1a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ArrNet_use.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
